<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4. 使用 PopRT &mdash; Title</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="_static/table_styling.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom_rtd.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/js/graphcore.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. Features" href="features/index.html" />
    <link rel="prev" title="3. 快速开始" href="quick_start.html" />
     
    <script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1074732,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PX5BPGW');</script>
    <!-- End Google Tag Manager -->

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
  <a href="https://docs.graphcore.ai/" class="icon icon-home" title="Back to Documents Home"><img src="_static/graphcorelogo-html.png" class="logo" alt="Logo"/></a>


<div class="homelink"><a href="index.html">POPRT USER GUIDE</a></div>


  
  
    <div class="version">
      Version: 1.5.0
    </div>
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">1. 简介</a><ul>
<li class="toctree-l2"><a class="reference internal" href="overview.html#id2">1.1. 背景</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#id3">1.2. 架构</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#id4">1.3. 工作流程</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">2. 安装</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#poprt-poplar-sdk">2.1. PopRT 和 Poplar SDK 版本的对应关系</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#docker">2.2. 从 Docker 镜像快速开始</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#host-poprt">2.3. 在 Host 上安装 PopRT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#for-ubuntu-20-04">2.3.1. For Ubuntu 20.04</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">3. 快速开始</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#id2">3.1. 主要参数介绍</a></li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#id3">3.2. 转换并运行模型</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#onnx">3.2.1. 下载 ONNX 模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#id4">3.2.2. 获取 ONNX 模型输入输出信息</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#shape">3.2.3. 指定输入 shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#id5">3.2.4. 指定模型精度</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#id6">3.2.5. 运行模型</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#popef">3.2.6. 导出 PopEF</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#id7">3.3. 快速部署</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#id8">3.3.1. 运行导出的 PopEF</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#id9">3.3.2. 运行转换后的 ONNX 模型</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#python-api">3.4. Python API 示例</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. 使用 PopRT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#id1">4.1. 使用方法</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#cli">4.1.1. CLI 使用</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Named Arguments">Named Arguments</a></li>
<li class="toctree-l4"><a class="reference internal" href="#Sub-commands:">Sub-commands:</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#tf2onnx">tf2onnx</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="features/index.html">5. Features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="features/passes.html">5.1. Passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/passes.html#pass">5.1.1. Pass 抽象</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/fp8.html">5.2. FP8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#ipu-fp8">5.2.1. IPU FP8 类型介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#id1">5.2.2. FP8 量化介绍</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#fp32-fp8">5.2.3. FP32 模型转 FP8 模型的流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#id2">5.2.4. FP8 模型转换工具使用方法</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#id3">5.2.5. FP8 模型转换精度调试经验</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/overlap_io.html">5.3. Overlap I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#id1">5.3.1. 原理</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#io-tiles">5.3.2. 配置 IO Tiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#id2">5.3.3. 调试</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#id3">5.3.4. 并发请求</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#id4">5.3.5. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/dynamic_batch_size.html">5.4. Dynamic batch size</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/dynamic_batch_size.html#id1">5.4.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/dynamic_batch_size.html#id3">5.4.2. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/packing.html">5.5. Packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#id1">5.5.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#packing-unpacking">5.5.2. Packing 及 unpacking</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#transformer-based-nlp-models">5.5.3. Transformer-based NLP models</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#id2">5.5.4. 如何使用 packing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#id3">下载模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#id4">转换模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#id5">运行模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/cpu_packing.html">5.6. CPU packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#id1">5.6.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#id2">5.6.2. 功能模块介绍</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#id3">1. 超时处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#id4">2. 用户数据预处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#id5">3. 数据累积</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#pack">4. Pack 后处理</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#id6">5.6.3. Pack 算法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#id7">1. 首尾相连的 pack 方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#firstfit-pack">2. FirstFit pack 方法</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#nextfit-pack">3. NextFit pack 方法</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#id8">5.6.4. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/model_fusion.html">5.7. Model fusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/model_fusion.html#poprt">5.7.1. 实现 PopRT 模型融合</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/model_fusion.html#id1">5.7.2. 实现 PopRT runtime 融合模型推理</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_ops.html">5.8. Custom operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_ops.html#id1">5.8.1. 编写自定义算子</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_ops.html#leakyrelu-op-onnx">创建一个带有 <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> OP 的 ONNX 模型文件</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_ops.html#poprt">在 PopRT 中使用自定义算子</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_onnx_pass.html">5.9. Custom passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_onnx_pass.html#id1">5.9.1. 实现 custom passes</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_onnx_pass.html#id2">5.9.2. 使用 custom passes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_onnx_pass.html#poprt-cli-custom-passes">在 PopRT CLI 中使用 custom passes</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_onnx_pass.html#python-api-custom-passes">在 Python API 中使用 custom passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_pattern.html">5.10. Custom patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_pattern.html#custom-popart-patterns">5.10.1. 实现 custom PopART patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_pattern.html#poprt-custom-popart-patterns">5.10.2. 在 PopRT 中使用 custom PopART patterns</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#patterncreator-pattern">方法一: 在 <code class="docutils literal notranslate"><span class="pre">PatternCreator</span></code> 设置 pattern 默认使能</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#python-api-pattern">方法二: 使用 Python API 启用或关闭指定的 pattern</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#cli-pattern">方法三: 通过 CLI 命令行参数启用或关闭指定的 pattern</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_transform.html">5.11. Custom transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_transform.html#custom-popart-transform">5.11.1. 实现 custom PopART transform</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_transform.html#poprt-custom-transform">5.11.2. 在 PopRT 中使用 custom transform</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/manual_sharding.html">5.12. Manual sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#sharding">5.12.1. Sharding / 模型并行</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#pipelining">5.12.2. Pipelining / 流水线并行</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#id3">5.12.3. Manual sharding 流程</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#id4">5.12.4. 配置 manual sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/manual_sharding.html#poprt-cli-manual-sharding">通过 PopRT CLI 配置 manual sharding</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/manual_sharding.html#poprt-converter-sharder-api-manual-sharding">通过 <code class="docutils literal notranslate"><span class="pre">poprt.converter.Sharder</span></code> API 配置 manual sharding</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#id5">5.12.5. 示例</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/error_handling.html">5.13. Error handling</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/error_handling.html#id1">5.13.1. 背景</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/error_handling.html#id2">5.13.2. 相关的错误处理方式</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/frontend.html">5.14. PopRT frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/frontend.html#onnx-frontend">5.14.1. ONNX frontend</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/frontend.html#tensorflow-frontend">5.14.2. TensorFlow frontend</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/frontend.html#poprt-cli-tensorflow">通过 PopRT CLI 加载 TensorFlow 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/frontend.html#poprt-frontend-api-tensorflow">通过 <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> API 加载 TensorFlow 模型</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/auto_sharding.html">5.15. Auto sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#id1">5.15.1. 模型并行</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#id2">5.15.2. Auto sharding 原理介绍</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#id3">备选点策略</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#id4">切分方案遍历策略</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#id5">5.15.3. Auto sharding 使用方法</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#id6">参数介绍</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#id7">举例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/model_debugger.html">5.16. Model debugger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/model_debugger.html#id1">5.16.1. 使用方法</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/model_debugger.html#id2">5.16.2. 使用示例</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python_api.html">6. Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-module">6.1. <code class="docutils literal notranslate"><span class="pre">poprt</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-compiler-module">6.2. <code class="docutils literal notranslate"><span class="pre">poprt.compiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-runtime-module">6.3. <code class="docutils literal notranslate"><span class="pre">poprt.runtime</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-frontend-module">6.4. <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-backends-module">6.5. <code class="docutils literal notranslate"><span class="pre">poprt.backends</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-quantizer-module">6.6. <code class="docutils literal notranslate"><span class="pre">poprt.quantizer</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-passes-module">6.7. <code class="docutils literal notranslate"><span class="pre">poprt.passes</span></code> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python_api.html#built-in-passes">6.7.1. Built-in passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cxx_api.html">7. C++ API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#poprt-compiler">7.1. PopRT compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#executable">7.2. Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#poprt-runtime">7.3. PopRT runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cxx_api.html#devicemanager">7.3.1. DeviceManager</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="history.html">8. 文档修订记录</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal.html">9. Trademarks &amp; copyright</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">POPRT USER GUIDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="poprt">
<span id="instructions"></span><h1><span class="section-number">4. </span>使用 PopRT<a class="headerlink" href="#poprt" title="Permalink to this headline"></a></h1>
<p>PopRT 成功安装后, 可以按照下面的说明使用 PopRT CLI.</p>
<section id="id1">
<h2><span class="section-number">4.1. </span>使用方法<a class="headerlink" href="#id1" title="Permalink to this headline"></a></h2>
<section id="cli">
<h3><span class="section-number">4.1.1. </span>CLI 使用<a class="headerlink" href="#cli" title="Permalink to this headline"></a></h3>
<p><p>poprt 是用于帮助快速部署 ONNX 模型到 IPU 上的工具.</p>
</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">poprt</span>
       <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">apply_hcsr</span> <span class="n">APPLY_HCSR</span> <span class="p">[</span><span class="n">APPLY_HCSR</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">available_memory_proportion</span> <span class="n">AVAILABLE_MEMORY_PROPORTION</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batch_axis</span> <span class="n">BATCH_AXIS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batches_per_step</span> <span class="n">BATCHES_PER_STEP</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">calibration_with_data</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">calibration_loss_type</span> <span class="p">{</span><span class="n">mse</span><span class="p">,</span><span class="n">mae</span><span class="p">,</span><span class="n">snr</span><span class="p">,</span><span class="n">kld</span><span class="p">,</span><span class="n">cos_dist</span><span class="p">,</span><span class="n">gptq</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">check</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">checkpoints</span> <span class="n">CHECKPOINTS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">compiler_options</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">config_yaml</span> <span class="n">CONFIG_YAML</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">convert_version</span> <span class="n">CONVERT_VERSION</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_library_so_paths</span> <span class="n">CUSTOM_LIBRARY_SO_PATHS</span> <span class="p">[</span><span class="n">CUSTOM_LIBRARY_SO_PATHS</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_pass_config</span> <span class="n">CUSTOM_PASS_CONFIG</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_shape_inference</span> <span class="n">CUSTOM_SHAPE_INFERENCE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">data_preprocess</span> <span class="n">DATA_PREPROCESS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">disable_compilation_progress_bar</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">disable_fast_norm</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">eightbitsio</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_if_with_same_cond</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_compress_pattern</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_erf_gelu</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_insert_remap</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">export_popef</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fold_periodic_initializer</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp16_skip_op_types</span> <span class="n">FP16_SKIP_OP_TYPES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_avoid_overflow_patterns</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp8_skip_op_names</span> <span class="n">FP8_SKIP_OP_NAMES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp8_params</span> <span class="n">FP8_PARAMS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">framework</span> <span class="n">FRAMEWORK</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">infer_shape_ahead</span><span class="p">]</span>
       <span class="p">[</span><span class="o">-</span><span class="n">i</span> <span class="n">INPUT_MODEL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">input_shape</span> <span class="n">INPUT_TENSOR_NAME</span> <span class="o">=</span> <span class="n">INPUT_SHAPE</span> <span class="p">[</span><span class="n">INPUT_TENSOR_NAME</span> <span class="o">=</span> <span class="n">INPUT_SHAPE</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">ipu_version</span> <span class="p">{</span><span class="n">ipu2</span><span class="p">,</span><span class="n">ipu21</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">list_all_passes</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">logging_level</span> <span class="p">{</span><span class="n">DEBUG</span><span class="p">,</span><span class="n">INFO</span><span class="p">,</span><span class="n">WARNING</span><span class="p">,</span><span class="n">ERROR</span><span class="p">,</span><span class="n">CRITICAL</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">manual_sharding_config</span> <span class="n">MANUAL_SHARDING_CONFIG</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">max_tensor_size</span> <span class="n">MAX_TENSOR_SIZE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">num_io_tiles</span> <span class="n">NUM_IO_TILES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">num_of_layers_keep_fp16</span> <span class="n">NUM_OF_LAYERS_KEEP_FP16</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">only_manual_sharding</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">optimize_internal_exchange_code</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">output_dir</span> <span class="n">OUTPUT_DIR</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">output_model</span> <span class="n">OUTPUT_MODEL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">pack_args</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">passes</span> <span class="n">PASSES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">perf_tuner</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">popart_options</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">precision</span> <span class="p">{</span><span class="n">fp32</span><span class="p">,</span><span class="n">fp16</span><span class="p">,</span><span class="n">fp8</span><span class="p">,</span><span class="n">fp8_weight</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">precision_compare</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">print_completion</span> <span class="p">{</span><span class="n">bash</span><span class="p">,</span><span class="n">zsh</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">remap_mode</span> <span class="n">REMAP_MODE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">remove_outputs</span> <span class="n">REMOVE_OUTPUTS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">run</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">serialize_matmul</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">serialize_matmul_add</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_matmul</span> <span class="n">MERGE_MATMUL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_matmul_add</span> <span class="n">MERGE_MATMUL_ADD</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_moe</span> <span class="n">MERGE_MOE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">show</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">show_io_stat</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">skip_passes</span> <span class="n">SKIP_PASSES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">-</span><span class="n">v</span><span class="p">]</span>
       <span class="p">{</span><span class="n">tf2onnx</span><span class="p">}</span>
       <span class="o">...</span>
</pre></div>
</div>
<section id="Named Arguments">
<h4>Named Arguments<a class="headerlink" href="#Named Arguments" title="Permalink to this headline"></a></h4>
<dl class="option-list">
<dt><kbd>--apply_hcsr</kbd></dt>
<dd><p>应用 <code class="code docutils literal notranslate"><span class="pre">apply_host_concat_split</span></code> pass, 参数格式为: dtype,shape,[num(optional)].
例如: <code class="code docutils literal notranslate"><span class="pre">--apply_hcsr</span> <span class="pre">fp32,[512,1],50</span> <span class="pre">fp32,[512,5]</span></code>. 默认值 None.</p>
</dd>
<dt><kbd>--available_memory_proportion</kbd></dt>
<dd><p>设置 MatMul/Conv/Gemm 算子的可用内存比例. 默认值 None.</p>
</dd>
<dt><kbd>--batch_size</kbd></dt>
<dd><p>Set the batch size for all inputs. Works with the batch_axis parameter.</p>
</dd>
<dt><kbd>--batch_axis</kbd></dt>
<dd><p>Specify the batch axis for all inputs. Works with the batch_size parameter.</p>
</dd>
<dt><kbd>--batches_per_step</kbd></dt>
<dd><p>设置 batches_per_step, 当前支持在导出 PopEF 时设置. 默认值 1.</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--calibration_with_data</kbd></dt>
<dd><p>使用校验数据对 fp8 模型进行校准,
需注意只有将 precision 设置为 fp8/fp8_weight 时该参数才有效, 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--calibration_loss_type</kbd></dt>
<dd><p>Possible choices: mse, mae, snr, kld, cos_dist, gptq</p>
<p>选择校验损失类型, 可选为 mse/mae/snr/kld/cos_dist/gptq, 其中 gptq 只能用于 fp8_weight 的量化校验, 默认值 kld.</p>
<p>Default: “kld”</p>
</dd>
<dt><kbd>--check</kbd></dt>
<dd><p>使能正确性检查, 当前只支持检查 popart_dependent_process 之前的 pass. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--checkpoints</kbd></dt>
<dd><p>将中间层的 tensor name 加入模型输出, 用于精度调试. 默认值 None.
例如 –checkpoints StatefulPartitionedCall/model_1/Embedding-Token/embedding_lookup:0.</p>
</dd>
<dt><kbd>--compiler_options</kbd></dt>
<dd><p>设置 PopRT 编译选项.</p>
</dd>
<dt><kbd>--config_yaml</kbd></dt>
<dd><p>通过 yaml 文件配置参数.</p>
</dd>
<dt><kbd>--convert_version</kbd></dt>
<dd><p>设置转换后模型的 ONNX Opset version. 默认值 11.</p>
<p>Default: 11</p>
</dd>
<dt><kbd>--custom_library_so_paths</kbd></dt>
<dd><p>设置自定义动态库的路径, 默认值 None.</p>
</dd>
<dt><kbd>--custom_pass_config</kbd></dt>
<dd><p>配置自定义 Pass 的配置文件路径.</p>
</dd>
<dt><kbd>--custom_shape_inference</kbd></dt>
<dd><p>设置自定义 Op Shape-Inference 的 Python 脚本路径.</p>
</dd>
<dt><kbd>--data_preprocess</kbd></dt>
<dd><p>选择量化所需的预处理后的校准数据, 要求为 pickle 格式, 存储为形如 {input_1: ndarray, input_2: ndarray,…} 的字典.</p>
</dd>
<dt><kbd>--disable_compilation_progress_bar</kbd></dt>
<dd><p>编译时不显示进度条.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--disable_fast_norm</kbd></dt>
<dd><p>禁用将 Layernorm 算子转换为 FastNorm 算子. 默认不禁用.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--eightbitsio</kbd></dt>
<dd><p>使能 8bit IO, 目前仅支持 ResNet50. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--merge_if_with_same_cond</kbd></dt>
<dd><p>使能合并使用同一个条件的多个 If Ops. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_compress_pattern</kbd></dt>
<dd><p>使能将 Compress Op 替换成 MaskCompress Op. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_erf_gelu</kbd></dt>
<dd><p>使能将 Erf Gelu 模式替换为 Gelu Op. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_insert_remap</kbd></dt>
<dd><p>使能自动插入 remap 以改善 tensor layout. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--export_popef</kbd></dt>
<dd><p>使能在转换过程中生成 PopEF 离线模型文件. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fold_periodic_initializer</kbd></dt>
<dd><p>折叠存在周期性数据的 initializer 节省 Always-Live 内存. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fp16_skip_op_types</kbd></dt>
<dd><p>指定 fp16 模式下需要保留 fp32 的 Op 类型. 默认值 None. 例如 –fp16_skip_op_types GroupNormalization,Gelu.</p>
</dd>
<dt><kbd>--enable_avoid_overflow_patterns</kbd></dt>
<dd><p>使能在 fp16 模式将某些容易溢出的 pattern 保留 fp32 类型. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fp8_skip_op_names</kbd></dt>
<dd><p>指定 fp8 模式下需要保留 fp16/fp32 的 Op 名称. 默认值 None. 例如 –fp8_skip_op_names Conv_1,Conv_2.</p>
</dd>
<dt><kbd>--fp8_params</kbd></dt>
<dd><p>设置 fp8 模型的参数. 格式为 input_format,weight_format,input_scale,weight_scale. 默认值 F143,F143,0,0.
分别设置 fp8 conv/matmul/gemm 输入和权重的格式 (F143/F152) 及 scale(int). 例如 –fp8_params F143,F143,0,0.</p>
<p>Default: “F143,F143,-1,-1”</p>
</dd>
<dt><kbd>--framework</kbd></dt>
<dd><p>指定加载模型所使用的框架.</p>
<p>Default: “onnx”</p>
</dd>
<dt><kbd>--infer_shape_ahead</kbd></dt>
<dd><p>转换过程中, 根据模型的输入 shape 首先进行常量折叠和形状推导. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>-i, --input_model</kbd></dt>
<dd><p>被转换模型的路径.</p>
</dd>
<dt><kbd>--input_shape</kbd></dt>
<dd><p>设置模型的输入 shape. 默认值 None. 如果模型输入可变, 建议设置模型输入 shape.
设置格式为 –input_shape ${INPUT_TENSOR_NAME_1}=${INPUT_SHAPE_1} ${INPUT_TENSOR_NAME_2}=${INPUT_SHAPE_2} …
例如 –input_shape input_ids=1,512 attention_mask=1,512.</p>
</dd>
<dt><kbd>--ipu_version</kbd></dt>
<dd><p>Possible choices: ipu2, ipu21</p>
<p>指定 ipu 版本, ipu2 对应 Bow2000/M2000, ipu21 对应 C600, 默认值 ipu2.</p>
<p>Default: “ipu2”</p>
</dd>
<dt><kbd>--list_all_passes</kbd></dt>
<dd><p>列出所有已注册的 Pass. NOTE: 目前仅支持自定义选择部分 Pass, 参考 –passes.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--logging_level</kbd></dt>
<dd><p>Possible choices: DEBUG, INFO, WARNING, ERROR, CRITICAL</p>
<p>设置日志级别. 默认值 WARNING.</p>
<p>Default: “WARNING”</p>
</dd>
<dt><kbd>--manual_sharding_config</kbd></dt>
<dd><p>设置 Sharding 和 Pipelining 配置文件(yaml)路径. 默认为 None.</p>
</dd>
<dt><kbd>--max_tensor_size</kbd></dt>
<dd><p>设置 constant_folding 时可以生成的 tensor 的最大 size(单位为 bytes). 默认为-1, 即不限制生成 tensor 的最大 size.
例如 –max_tensor_size 41943040, 表示限制 constant_folding 生成的最大 tensor 为 40MB.</p>
<p>Default: -1</p>
</dd>
<dt><kbd>--num_io_tiles</kbd></dt>
<dd><p>设置 IO Tiles 的数量, 默认为 0. 如果大于 0, IPU 会运行在 OverlapIO 模式.
更多关于 overlap io 的信息可以见: <a class="reference external" href="https://docs.graphcore.ai/projects/popart-user-guide/en/latest/overlap_io.html">https://docs.graphcore.ai/projects/popart-user-guide/en/latest/overlap_io.html</a>.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--num_of_layers_keep_fp16</kbd></dt>
<dd><p>FP8 量化时指定 topk 大的损失对应的层为 FP16, 例如需要设置前 3 层量化损失最大的层为 FP16,
该值即设置为 3. 默认值是 0.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--only_manual_sharding</kbd></dt>
<dd><p>当前命令行仅对模型进行 Sharding 和 Pipelining 设置. 如果使能 <cite>only_manual_sharding</cite>, 当前命令行仅支持 <cite>–input_model</cite>,
<cite>–output_model</cite>, <cite>–output_dir</cite> 和 <cite>–manual_sharding_config</cite> 参数. <cite>–output_model</cite> 和 <cite>–output_dir</cite> 是可选的.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--optimize_internal_exchange_code</kbd></dt>
<dd><p>优化内部数据交换代码占用的内存. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--output_dir</kbd></dt>
<dd><p>设置输出目录, 转换后的模型文件和 PopEF 文件 (如果开启相关选项) 会保存在这里. 默认指向当前目录.</p>
<p>Default: “./”</p>
</dd>
<dt><kbd>--output_model</kbd></dt>
<dd><p>转换后模型的名称, 将放在 –output_dir 目录下. NOTE: 这里只能指定模型名称, 设置转换后模型的保存路径应使用 –output_dir.</p>
</dd>
<dt><kbd>--pack_args</kbd></dt>
<dd><p>使能 packed transformer. 默认为不使能.
例如 –pack_args max_valid_num=90  segment_max_size=64 efficiency_priority=false.</p>
</dd>
<dt><kbd>--passes</kbd></dt>
<dd><p>选择在转换过程中需要用到的 Custom Pass, 参考 –list_all_passes. 默认值 None.</p>
</dd>
<dt><kbd>--perf_tuner</kbd></dt>
<dd><p>使能性能选优, 当前尚未实现. 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--popart_options</kbd></dt>
<dd><p>设置 PopART Session 编译选项. 默认值 None.</p>
</dd>
<dt><kbd>--precision</kbd></dt>
<dd><p>Possible choices: fp32, fp16, fp8, fp8_weight</p>
<p>量化为目标精度模型, 可选项 fp32 / fp16 / fp8 /fp8_weight, 默认值 fp32.
例如 –precision fp16.</p>
<p>Default: “fp32”</p>
</dd>
<dt><kbd>--precision_compare</kbd></dt>
<dd><p>对比原始模型和转换后的模型在 conv/matmul/gemm 处的输出损失,
需注意只有将 precision 设置为 fp8/fp8_weight 时该参数才有效.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--print_completion</kbd></dt>
<dd><p>Possible choices: bash, zsh</p>
<p>输出 shell 补全脚本.</p>
</dd>
<dt><kbd>--remap_mode</kbd></dt>
<dd><p>设置 remap 的模式, 仅当使能 enable_insert_remap 的条件下生效.
按照 ‘before/after’+’_’+’op_type’ 指定插入 remap 的模式. 默认 after_matmul.
例如 –remap_mode after_matmul,before_softmax,after_concat .</p>
<p>Default: “after_matmul”</p>
</dd>
<dt><kbd>--remove_outputs</kbd></dt>
<dd><p>移除模型中的输出和冗余的节点, 例如 –remove_outputs output_1,output_2.</p>
</dd>
<dt><kbd>--run</kbd></dt>
<dd><p>使能随机数运行模型, 默认不使能.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--serialize_matmul</kbd></dt>
<dd><p>使能 MatMul 序列化节省片上内存. 默认不使能.
按 ${OP_NAME}=${FACTOR}/${MODE}/${KEEP_PRECISION} 或
${OP_NAME}=${FACTOR}/${MODE} 或 ${OP_NAME}=${FACTOR}
对指定的 MatMul Op 进行序列化设置.
Mode 可选项有 input_channels, output_channels, reducing_dim, none.  默认值是 output_channels.
KEEP_PRECISION 可选项有 True, False. 默认值是 False.
例如 –serialize_matmul MatMul_1=4/input_channels/True MatMul_2=4/input_channels MatMul_3=4.</p>
</dd>
<dt><kbd>--serialize_matmul_add</kbd></dt>
<dd><p>使能序列化 MatMul weights 和 Add bias 以节省片上内存, 按 weights 最后一维进行序列化.
默认不使能. 按 ${MATMUL_OP_NAME}/${ADD_OP_NAME}=${FACTOR} 对指定的 MatMul 和 Add 进行序列化设置.
例如 –serialize_matmul_add MatMul_1/Add_2=4.</p>
</dd>
<dt><kbd>--merge_matmul</kbd></dt>
<dd><p>使能合并多个 MatMul 算子以节省时间, 默认不使能.
按 ${MATMUL_OP_NAME1},${MATMUL_OP_NAME2} 指定需要合并的 MatMul 算子.
例如 –merge_matmul MatMul_1,MatMul_2.</p>
</dd>
<dt><kbd>--merge_matmul_add</kbd></dt>
<dd><p>使能合并多个 MatMul/Add 算子对以节省时间, 默认不使能.
按 ${MATMUL_OP_NAME1},${ADD_OP_NAME1},${MATMUL_OP_NAME2},${ADD_OP_NAME2} 指定需要合并 MatMul/Add 算子对.
例如 –merge_matmul_add MatMul_1,Add_1,MatMul_2,Add_2’.</p>
</dd>
<dt><kbd>--merge_moe</kbd></dt>
<dd><p>使能合并Mixture-of-Experts结构以节省时间, 默认不使能.
按 ${EXPERT_BEGIN_OP_NAME1},${EXPERT_END_OP_NAME1},${EXPERT_BEGIN_OP_NAME2},${EXPERT_END_OP_NAME2} 指定需要合并的 expert.
例如 –merge_moe MatMul_1,Add_1,MatMul_2,Add_2’.</p>
</dd>
<dt><kbd>--show</kbd></dt>
<dd><p>输出模型的输入输出信息.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--show_io_stat</kbd></dt>
<dd><p>输出模型的输入/输出统计信息.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--skip_passes</kbd></dt>
<dd><p>指定跳过特定的 passes. 默认值 None. 例如 –skip_passes layer_norm_pattern.</p>
</dd>
<dt><kbd>-v, --version</kbd></dt>
<dd><p>显示工具的版本.</p>
<p>Default: False</p>
</dd>
</dl>
</section>
<section id="Sub-commands:">
<h4>Sub-commands:<a class="headerlink" href="#Sub-commands:" title="Permalink to this headline"></a></h4>
<section id="tf2onnx">
<h5>tf2onnx<a class="headerlink" href="#tf2onnx" title="Permalink to this headline"></a></h5>
<p>tf2onnx 将 TensorFlow 模型转换为 ONNX 模型.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">poprt</span> <span class="n">tf2onnx</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">saved_model</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">signature_def</span> <span class="n">SIGNATURE_DEF</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tag</span> <span class="n">TAG</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">inputs</span> <span class="n">INPUTS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">outputs</span> <span class="n">OUTPUTS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">opset</span> <span class="n">OPSET</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">inputs_as_nchw</span> <span class="n">INPUTS_AS_NCHW</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">outputs_as_nchw</span> <span class="n">OUTPUTS_AS_NCHW</span><span class="p">]</span>
</pre></div>
</div>
<section id="Named Arguments_repeat1">
<h6>Named Arguments<a class="headerlink" href="#Named Arguments_repeat1" title="Permalink to this headline"></a></h6>
<dl class="option-list">
<dt><kbd>--saved_model</kbd></dt>
<dd><p>使能加载 TensorFlow Saved Model, 模型路径仍然由 –input_model 指定.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--signature_def</kbd></dt>
<dd><p>指定 TensorFlow Saved Model 所使用的 signature_def.</p>
</dd>
<dt><kbd>--tag</kbd></dt>
<dd><p>指定 TensorFlow Saved Model 所使用的 tag.</p>
</dd>
<dt><kbd>--inputs</kbd></dt>
<dd><p>model input_names (optional for saved_model).</p>
</dd>
<dt><kbd>--outputs</kbd></dt>
<dd><p>指定 TensorFlow 模型的输出名字, 对于 Saved Model 为可选项.</p>
</dd>
<dt><kbd>--opset</kbd></dt>
<dd><p>设置转换后模型的 ONNX Opset version. 默认值 11.</p>
<p>Default: 11</p>
</dd>
<dt><kbd>--inputs_as_nchw</kbd></dt>
<dd><p>指定需要转换为 NCHW 格式的模型输入, 不同输入之间使用 , 隔开.</p>
</dd>
<dt><kbd>--outputs_as_nchw</kbd></dt>
<dd><p>指定需要转换为 NCHW 格式的模型输出, 不同输出之间使用 , 隔开.</p>
</dd>
</dl>
</section>
</section>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start.html" class="btn btn-neutral float-left" title="3. 快速开始" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="features/index.html" class="btn btn-neutral float-right" title="5. Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script id="hs-script-loader" async defer src="//js.hs-scripts.com/729091.js"></script>
    <script defer>
        if (typeof mutationObserver !== 'undefined')
            mutationObserver.observe(document.querySelector("div.rst-other-versions"), {childList: true, subtree: true})
        if (typeof updateDocumentLinks !== 'undefined')
            updateDocumentLinks()
        let search = document.querySelector("form#rtd-search-form > input[name='q']")
        if (document.location.pathname.startsWith("/projects/"))
          search.placeholder = "Search this document";
        else
          search.placeholder = "Search all documents";
    </script>


</body>
</html>