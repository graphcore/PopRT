<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.8. Custom operations &mdash; Title</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/table_styling.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom_rtd.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/graphcore.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.9. Custom passes" href="custom_onnx_pass.html" />
    <link rel="prev" title="5.7. Model fusion" href="model_fusion.html" />
     
    <script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1074732,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PX5BPGW');</script>
    <!-- End Google Tag Manager -->

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
  <a href="https://docs.graphcore.ai/" class="icon icon-home" title="Back to Documents Home"><img src="../_static/graphcorelogo-html.png" class="logo" alt="Logo"/></a>


<div class="homelink"><a href="../index.html">POPRT USER GUIDE</a></div>


  
  
    <div class="version">
      Version: 1.4.0
    </div>
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#background">1.1. Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#architecture">1.2. Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#workflow">1.3. Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">2. Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#compatibility-of-poprt-with-the-poplar-sdk">2.1. Compatibility of PopRT with the Poplar SDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-start-with-a-docker-image">2.2. Quick start with a Docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#install-poprt-on-host-server">2.3. Install PopRT on host server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#for-ubuntu-20-04">2.3.1. For Ubuntu 20.04</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poplar-sdk">Install Poplar SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#enable-the-sdk">Enable the SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poprt">Install PopRT</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">3. Quick start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#cli-parameters">3.1. CLI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#convert-and-run-model">3.2. Convert and run model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#download-onnx-model">3.2.1. Download ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#obtain-input-and-output-information-for-onnx-model">3.2.2. Obtain input and output information for ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-input-shape">3.2.3. Specify input shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-model-accuracy">3.2.4. Specify model accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-model">3.2.5. Run model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#export-popef-model">3.2.6. Export PopEF model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#quick-deployment">3.3. Quick deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-exported-popef-model">3.3.1. Run exported PopEF model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-converted-onnx-model">3.3.2. Run converted ONNX model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#python-api-example">3.4. Python API example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../instructions.html">4. Command line interface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Named Arguments">4.1. Named Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Sub-commands:">4.2. Sub-commands:</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../instructions.html#tf2onnx">4.2.1. tf2onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../instructions.html#Named Arguments_repeat1">Named Arguments</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">5. Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="passes.html">5.1. Passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="passes.html#pass-abstract">5.1.1. Pass abstract</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="fp8.html">5.2. FP8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#ipu-fp8-type">5.2.1. IPU FP8 type</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-quantisation">5.2.2. FP8 quantisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#converting-an-fp32-model-to-fp8">5.2.3. Converting an FP32 model to FP8</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-model-conversion-tool">5.2.4. FP8 model conversion tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#debugging-fp8-model-conversion-problems">5.2.5. Debugging FP8 model conversion problems</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="overlap_io.html">5.3. Overlap I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#principle">5.3.1. Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#configuring-i-o-tiles">5.3.2. Configuring I/O tiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#debugging">5.3.3. Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#concurrent-requests">5.3.4. Concurrent requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#example">5.3.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dynamic_batch_size.html">5.4. Dynamic batch size</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#background">5.4.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#example">5.4.2. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="packing.html">5.5. Packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="packing.html#background">5.5.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#packing-and-unpacking">5.5.2. Packing and unpacking</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#transformer-based-nlp-models">5.5.3. Transformer-based NLP models</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#how-to-use-packing">5.5.4. How to use packing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="packing.html#downloading-the-model">Downloading the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#converting-the-model">Converting the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#running-the-model">Running the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpu_packing.html">5.6. CPU packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#background">5.6.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#functional-modules">5.6.2. Functional modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#timeout-processing">Timeout processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#user-data-preprocessing">User data preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#data-accumulation">Data accumulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#post-packing-processing">Post-packing processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#packing-algorithms">5.6.3. Packing algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#end-to-end-method">End-to-end method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#firstfit-method">FirstFit method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#nextfit-method">NextFit method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#examples">5.6.4. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_fusion.html">5.7. Model fusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-model-fusion">5.7.1. Implementing PopRT model fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-runtime-fusion-model-inference">5.7.2. Implementing PopRT Runtime fusion model inference</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.8. Custom operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#writing-custom-operators">5.8.1. Writing custom operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#create-the-onnx-model-file-with-the-leakyrelu-op">Create the ONNX model file with the <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> op</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#using-custom-operators-in-poprt">5.8.2. Using custom operators in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_onnx_pass.html">5.9. Custom passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#implementing-custom-passes">5.9.1. Implementing custom passes</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes">5.9.2. Using custom passes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-poprt-cli">Using custom passes in the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-python-api">Using custom passes in the Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_pattern.html">5.10. Custom patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#implementing-custom-popart-patterns">5.10.1. Implementing custom PopART patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#using-custom-popart-patterns-in-poprt">5.10.2. Using custom PopART patterns in PopRT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-1-use-patterncreator-to-enable-the-pattern-by-default">Method 1: Use <code class="docutils literal notranslate"><span class="pre">PatternCreator</span></code> to enable the pattern by default</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-2-configure-a-pattern-using-the-python-api">Method 2: Configure a pattern using the Python API</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-3-config-the-specified-pattern-using-cli">Method 3: Config the specified pattern using CLI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_transform.html">5.11. Custom transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#implementing-custom-popart-transforms">5.11.1. Implementing custom PopART transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#using-custom-transforms-in-poprt">5.11.2. Using custom transforms in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manual_sharding.html">5.12. Manual sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#sharding-and-model-parallelism">5.12.1. Sharding and model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#pipelining-and-pipeline-parallelism">5.12.2. Pipelining and pipeline parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#manual-sharding-process">5.12.3. Manual sharding process</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding">5.12.4. Configuring manual sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding-with-the-poprt-cli">Configuring manual sharding with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding-with-the-python-api">Configuring manual sharding with the Python API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#example">5.12.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="error_handling.html">5.13. Error handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="frontend.html">5.14. PopRT frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#onnx-frontend">5.14.1. ONNX frontend</a></li>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#tensorflow-frontend">5.14.2. TensorFlow frontend</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-the-poprt-cli">Loading a TensorFlow model with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-python-api">Loading a TensorFlow model with Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto_sharding.html">5.15. Auto-sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#model-parallelism">5.15.1. Model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#principle-of-auto-sharding">5.15.2. Principle of auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#alternative-nodes-strategy">Alternative nodes strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#traversal-strategy-of-sharding-scheme">Traversal strategy of sharding scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#using-auto-sharding">5.15.3. Using auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#auto-sharding-tool">Auto-sharding tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_debugger.html">5.16. Model debugger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#model-debugger-tool">5.16.1. Model Debugger tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#examples">5.16.2. Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../python_api.html">6. Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-module">6.1. <code class="docutils literal notranslate"><span class="pre">poprt</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-compiler-module">6.2. <code class="docutils literal notranslate"><span class="pre">poprt.compiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-runtime-module">6.3. <code class="docutils literal notranslate"><span class="pre">poprt.runtime</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-frontend-module">6.4. <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-backends-module">6.5. <code class="docutils literal notranslate"><span class="pre">poprt.backends</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-quantizer-module">6.6. <code class="docutils literal notranslate"><span class="pre">poprt.quantizer</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-passes-module">6.7. <code class="docutils literal notranslate"><span class="pre">poprt.passes</span></code> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python_api.html#built-in-passes">6.7.1. Built-in passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cxx_api.html">7. C++ API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-compiler">7.1. PopRT Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#executable">7.2. Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-runtime">7.3. PopRT Runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cxx_api.html#devicemanager">7.3.1. DeviceManager</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../history.html">8. Revision history</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal.html">9. Trademarks &amp; copyright</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POPRT USER GUIDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="custom-operations">
<span id="features-custom-ops"></span><h1><span class="section-number">5.8. </span>Custom operations<a class="headerlink" href="#custom-operations" title="Permalink to this headline"></a></h1>
<p>PopRT supports creation of custom operators. You will need to create a custom operation when your model contains an operator that is not supported in PopRT. In this case, you can write a custom operator and compile it into a dynamic link library. PopRT supports dynamic linking of this custom operator into PopRT with the command line.</p>
<p>Since PopRT uses PopART as the backend, the process of developing custom operators for PopRT is the same as that for PopART. Please refer to <a class="reference external" href="https://docs.graphcore.ai/projects/popart-user-guide/en/latest/custom_ops.html">Creating Custom Op in PopART</a> .</p>
<p>This section describes the process of developing custom operators for PopRT with an example.</p>
<section id="writing-custom-operators">
<h2><span class="section-number">5.8.1. </span>Writing custom operators<a class="headerlink" href="#writing-custom-operators" title="Permalink to this headline"></a></h2>
<p>Taking the custom operator named <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> as an example, you first need to write the C++ code for it:</p>
<div class="literal-block-wrapper docutils container" id="leaky-relu-custom-op-cpp">
<div class="code-block-caption"><span class="caption-number">Listing 5.8 </span><span class="caption-text">leaky_relu_custom_op.cpp</span><a class="headerlink" href="#leaky-relu-custom-op-cpp" title="Permalink to this code"></a></div>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="c1">// Copyright (c) 2020 Graphcore Ltd. All rights reserved.</span>
<span class="linenos">  2</span>
<span class="linenos">  3</span><span class="c1">// This example demonstrates how to create a custom operator for PopART, in this</span>
<span class="linenos">  4</span><span class="c1">// case a Leaky ReLU op that returns `x` for any element `x &gt;= 0` and `x *</span>
<span class="linenos">  5</span><span class="c1">// alpha` for any element `x &lt; 0`, where `alpha` is provided as a scalar</span>
<span class="linenos">  6</span><span class="c1">// attribute to the operator.</span>
<span class="linenos">  7</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popart/operatoridentifier.hpp&gt;</span>
<span class="linenos">  8</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popart/opmanager.hpp&gt;</span>
<span class="linenos">  9</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popart/opserialiser.hpp&gt;</span>
<span class="linenos"> 10</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popart/popx/opxmanager.hpp&gt;</span>
<span class="linenos"> 11</span>
<span class="linenos"> 12</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popops/ElementWise.hpp&gt;</span>
<span class="linenos"> 13</span><span class="cp">#include</span><span class="w"> </span><span class="cpf">&lt;popart/popx/opx.hpp&gt;</span>
<span class="linenos"> 14</span>
<span class="linenos"> 15</span><span class="k">namespace</span><span class="w"> </span><span class="nn">CustomOperators</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 16</span><span class="k">const</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">OperatorIdentifier</span><span class="w"> </span><span class="n">LeakyReluId</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">popart</span><span class="o">::</span><span class="n">Domain</span><span class="o">::</span><span class="n">ai_graphcore</span><span class="p">,</span>
<span class="linenos"> 17</span><span class="w">                                                </span><span class="s">&quot;LeakyRelu&quot;</span><span class="p">,</span>
<span class="linenos"> 18</span><span class="w">                                                </span><span class="mi">1</span><span class="p">};</span>
<span class="linenos"> 19</span><span class="p">}</span><span class="w"> </span><span class="c1">// namespace CustomOperators</span>
<span class="linenos"> 20</span>
<span class="linenos"> 21</span><span class="k">class</span><span class="w"> </span><span class="nc">LeakyReluOp</span><span class="p">;</span>
<span class="linenos"> 22</span><span class="k">class</span><span class="w"> </span><span class="nc">LeakyReluOpx</span><span class="p">;</span>
<span class="linenos"> 23</span>
<span class="linenos"> 24</span><span class="k">class</span><span class="w"> </span><span class="nc">LeakyReluOp</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">Op</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 25</span><span class="k">public</span><span class="o">:</span>
<span class="linenos"> 26</span><span class="w">  </span><span class="n">LeakyReluOp</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">OperatorIdentifier</span><span class="w"> </span><span class="o">&amp;</span><span class="n">_opid</span><span class="p">,</span>
<span class="linenos"> 27</span><span class="w">              </span><span class="kt">float</span><span class="w"> </span><span class="n">_alpha</span><span class="p">,</span>
<span class="linenos"> 28</span><span class="w">              </span><span class="k">const</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">Op</span><span class="o">::</span><span class="n">Settings</span><span class="w"> </span><span class="o">&amp;</span><span class="n">settings_</span><span class="p">)</span>
<span class="linenos"> 29</span><span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">Op</span><span class="p">(</span><span class="n">_opid</span><span class="p">,</span><span class="w"> </span><span class="n">settings_</span><span class="p">),</span><span class="w"> </span><span class="n">alpha</span><span class="p">(</span><span class="n">_alpha</span><span class="p">)</span><span class="w"> </span><span class="p">{}</span>
<span class="linenos"> 30</span>
<span class="linenos"> 31</span><span class="w">  </span><span class="n">std</span><span class="o">::</span><span class="n">unique_ptr</span><span class="o">&lt;</span><span class="n">Op</span><span class="o">&gt;</span><span class="w"> </span><span class="n">clone</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">final</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 32</span><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">LeakyReluOp</span><span class="o">&gt;</span><span class="p">(</span><span class="o">*</span><span class="k">this</span><span class="p">);</span>
<span class="linenos"> 33</span><span class="w">  </span><span class="p">}</span>
<span class="linenos"> 34</span>
<span class="linenos"> 35</span><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">setup</span><span class="p">()</span><span class="w"> </span><span class="k">final</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">outInfo</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">inInfo</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span><span class="w"> </span><span class="p">}</span>
<span class="linenos"> 36</span>
<span class="linenos"> 37</span><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">appendAttributes</span><span class="p">(</span><span class="n">popart</span><span class="o">::</span><span class="n">OpSerialiserBase</span><span class="w"> </span><span class="o">&amp;</span><span class="n">os</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 38</span><span class="w">    </span><span class="n">Op</span><span class="o">::</span><span class="n">appendAttributes</span><span class="p">(</span><span class="n">os</span><span class="p">);</span>
<span class="linenos"> 39</span><span class="w">    </span><span class="n">os</span><span class="p">.</span><span class="n">appendAttribute</span><span class="p">(</span><span class="s">&quot;alpha&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">getAlpha</span><span class="p">());</span>
<span class="linenos"> 40</span><span class="w">  </span><span class="p">}</span>
<span class="linenos"> 41</span>
<span class="linenos"> 42</span><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">appendOutlineAttributes</span><span class="p">(</span><span class="n">popart</span><span class="o">::</span><span class="n">OpSerialiserBase</span><span class="w"> </span><span class="o">&amp;</span><span class="n">os</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 43</span><span class="w">    </span><span class="n">Op</span><span class="o">::</span><span class="n">appendOutlineAttributes</span><span class="p">(</span><span class="n">os</span><span class="p">);</span>
<span class="linenos"> 44</span><span class="w">    </span><span class="n">os</span><span class="p">.</span><span class="n">appendAttribute</span><span class="p">(</span><span class="s">&quot;alpha&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">getAlpha</span><span class="p">());</span>
<span class="linenos"> 45</span><span class="w">  </span><span class="p">}</span>
<span class="linenos"> 46</span>
<span class="linenos"> 47</span><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">getSubgraphValue</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">final</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">getHighSubgraphValue</span><span class="p">();</span><span class="w"> </span><span class="p">}</span>
<span class="linenos"> 48</span>
<span class="linenos"> 49</span><span class="w">  </span><span class="kt">bool</span><span class="w"> </span><span class="n">requiresRandomSeed</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">override</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="nb">false</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="linenos"> 50</span>
<span class="linenos"> 51</span><span class="w">  </span><span class="c1">// Attributes</span>
<span class="linenos"> 52</span><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">getAlpha</span><span class="p">()</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">alpha</span><span class="p">;</span><span class="w"> </span><span class="p">}</span>
<span class="linenos"> 53</span>
<span class="linenos"> 54</span><span class="k">private</span><span class="o">:</span>
<span class="linenos"> 55</span><span class="w">  </span><span class="kt">float</span><span class="w"> </span><span class="n">alpha</span><span class="p">;</span>
<span class="linenos"> 56</span><span class="p">};</span>
<span class="linenos"> 57</span>
<span class="linenos"> 58</span><span class="k">namespace</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 59</span><span class="k">using</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">DataType</span><span class="p">;</span>
<span class="linenos"> 60</span><span class="k">using</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">OpDefinition</span><span class="p">;</span>
<span class="linenos"> 61</span>
<span class="linenos"> 62</span><span class="k">static</span><span class="w"> </span><span class="n">OpDefinition</span><span class="o">::</span><span class="n">DataTypes</span><span class="w"> </span><span class="n">T</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span><span class="n">DataType</span><span class="o">::</span><span class="n">FLOAT16</span><span class="p">,</span><span class="w"> </span><span class="n">DataType</span><span class="o">::</span><span class="n">FLOAT</span><span class="p">};</span>
<span class="linenos"> 63</span>
<span class="linenos"> 64</span><span class="k">static</span><span class="w"> </span><span class="n">OpDefinition</span>
<span class="linenos"> 65</span><span class="w">    </span><span class="n">leakyReluOpDef</span><span class="p">({</span><span class="n">OpDefinition</span><span class="o">::</span><span class="n">Inputs</span><span class="p">({{</span><span class="s">&quot;input&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="p">}}),</span>
<span class="linenos"> 66</span><span class="w">                    </span><span class="n">OpDefinition</span><span class="o">::</span><span class="n">Outputs</span><span class="p">({{</span><span class="s">&quot;output&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">T</span><span class="p">}}),</span>
<span class="linenos"> 67</span><span class="w">                    </span><span class="n">OpDefinition</span><span class="o">::</span><span class="n">Attributes</span><span class="p">({{</span><span class="s">&quot;alpha&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="s">&quot;*&quot;</span><span class="p">}}})});</span>
<span class="linenos"> 68</span>
<span class="linenos"> 69</span><span class="k">static</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">OpCreator</span><span class="o">&lt;</span><span class="n">LeakyReluOp</span><span class="o">&gt;</span><span class="w"> </span><span class="n">leakyReluOpCreator</span><span class="p">(</span>
<span class="linenos"> 70</span><span class="w">    </span><span class="n">popart</span><span class="o">::</span><span class="n">OpDefinitions</span><span class="p">({{</span><span class="n">CustomOperators</span><span class="o">::</span><span class="n">LeakyReluId</span><span class="p">,</span><span class="w"> </span><span class="n">leakyReluOpDef</span><span class="p">}}),</span>
<span class="linenos"> 71</span><span class="w">    </span><span class="p">[](</span><span class="k">const</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">OpCreatorInfo</span><span class="w"> </span><span class="o">&amp;</span><span class="n">info</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 72</span><span class="w">      </span><span class="c1">// default alpha is 10**(-2)</span>
<span class="linenos"> 73</span><span class="w">      </span><span class="kt">float</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">info</span><span class="p">.</span><span class="n">attributes</span><span class="p">.</span><span class="n">getAttribute</span><span class="o">&lt;</span><span class="n">popart</span><span class="o">::</span><span class="n">Attributes</span><span class="o">::</span><span class="n">Float</span><span class="o">&gt;</span><span class="p">(</span>
<span class="linenos"> 74</span><span class="w">          </span><span class="s">&quot;alpha&quot;</span><span class="p">,</span><span class="w"> </span><span class="mf">1e-2f</span><span class="p">);</span>
<span class="linenos"> 75</span><span class="w">      </span><span class="k">return</span><span class="w"> </span><span class="n">std</span><span class="o">::</span><span class="n">make_unique</span><span class="o">&lt;</span><span class="n">LeakyReluOp</span><span class="o">&gt;</span><span class="p">(</span><span class="n">info</span><span class="p">.</span><span class="n">opid</span><span class="p">,</span><span class="w"> </span><span class="n">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">info</span><span class="p">.</span><span class="n">settings</span><span class="p">);</span>
<span class="linenos"> 76</span><span class="w">    </span><span class="p">},</span>
<span class="linenos"> 77</span><span class="w">    </span><span class="nb">true</span><span class="p">);</span>
<span class="linenos"> 78</span><span class="p">}</span><span class="w"> </span><span class="c1">// namespace</span>
<span class="linenos"> 79</span>
<span class="linenos"> 80</span><span class="k">namespace</span><span class="w"> </span><span class="nn">pe</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nn">popops</span><span class="o">::</span><span class="nn">expr</span><span class="p">;</span>
<span class="linenos"> 81</span>
<span class="linenos"> 82</span><span class="k">class</span><span class="w"> </span><span class="nc">LeakyReluOpx</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="k">public</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">popx</span><span class="o">::</span><span class="n">Opx</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 83</span><span class="k">public</span><span class="o">:</span>
<span class="linenos"> 84</span><span class="w">  </span><span class="n">LeakyReluOpx</span><span class="p">(</span><span class="n">popart</span><span class="o">::</span><span class="n">Op</span><span class="w"> </span><span class="o">*</span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">popx</span><span class="o">::</span><span class="n">Devicex</span><span class="w"> </span><span class="o">*</span><span class="n">devicex</span><span class="p">)</span>
<span class="linenos"> 85</span><span class="w">      </span><span class="o">:</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">popx</span><span class="o">::</span><span class="n">Opx</span><span class="p">(</span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="n">devicex</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 86</span><span class="w">    </span><span class="n">verifyOp</span><span class="o">&lt;</span><span class="n">LeakyReluOp</span><span class="o">&gt;</span><span class="p">(</span><span class="n">op</span><span class="p">,</span><span class="w"> </span><span class="p">{</span><span class="n">CustomOperators</span><span class="o">::</span><span class="n">LeakyReluId</span><span class="p">});</span>
<span class="linenos"> 87</span><span class="w">  </span><span class="p">}</span>
<span class="linenos"> 88</span>
<span class="linenos"> 89</span><span class="w">  </span><span class="kt">void</span><span class="w"> </span><span class="n">grow</span><span class="p">(</span><span class="n">poplar</span><span class="o">::</span><span class="n">program</span><span class="o">::</span><span class="n">Sequence</span><span class="w"> </span><span class="o">&amp;</span><span class="n">prog</span><span class="p">)</span><span class="w"> </span><span class="k">const</span><span class="w"> </span><span class="k">final</span><span class="w"> </span><span class="p">{</span>
<span class="linenos"> 90</span>
<span class="linenos"> 91</span><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getOp</span><span class="o">&lt;</span><span class="n">LeakyReluOp</span><span class="o">&gt;</span><span class="p">();</span>
<span class="linenos"> 92</span>
<span class="linenos"> 93</span><span class="w">    </span><span class="n">poplar</span><span class="o">::</span><span class="n">Tensor</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">getInTensor</span><span class="p">(</span><span class="mi">0</span><span class="p">);</span>
<span class="linenos"> 94</span>
<span class="linenos"> 95</span><span class="w">    </span><span class="kt">float</span><span class="w"> </span><span class="n">alpha</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">op</span><span class="p">.</span><span class="n">getAlpha</span><span class="p">();</span>
<span class="linenos"> 96</span>
<span class="linenos"> 97</span><span class="w">    </span><span class="c1">// x &lt; 0.0f ? alpha * x : x</span>
<span class="linenos"> 98</span><span class="w">    </span><span class="k">auto</span><span class="w"> </span><span class="n">expression</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">pe</span><span class="o">::</span><span class="n">Select</span><span class="p">(</span><span class="n">pe</span><span class="o">::</span><span class="n">Mul</span><span class="p">(</span><span class="n">pe</span><span class="o">::</span><span class="n">Const</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span><span class="w"> </span><span class="n">pe</span><span class="o">::</span><span class="n">_1</span><span class="p">),</span>
<span class="linenos"> 99</span><span class="w">                                 </span><span class="n">pe</span><span class="o">::</span><span class="n">_1</span><span class="p">,</span>
<span class="linenos">100</span><span class="w">                                 </span><span class="n">pe</span><span class="o">::</span><span class="n">Lt</span><span class="p">(</span><span class="n">pe</span><span class="o">::</span><span class="n">_1</span><span class="p">,</span><span class="w"> </span><span class="n">pe</span><span class="o">::</span><span class="n">Const</span><span class="p">(</span><span class="mf">0.0f</span><span class="p">)));</span>
<span class="linenos">101</span>
<span class="linenos">102</span><span class="w">    </span><span class="n">popops</span><span class="o">::</span><span class="n">mapInPlace</span><span class="p">(</span><span class="n">graph</span><span class="p">(),</span>
<span class="linenos">103</span><span class="w">                       </span><span class="n">expression</span><span class="p">,</span>
<span class="linenos">104</span><span class="w">                       </span><span class="p">{</span><span class="n">input</span><span class="p">},</span>
<span class="linenos">105</span><span class="w">                       </span><span class="n">prog</span><span class="p">,</span>
<span class="linenos">106</span><span class="w">                       </span><span class="n">debugContext</span><span class="p">(</span><span class="s">&quot;LeakyRelu&quot;</span><span class="p">),</span>
<span class="linenos">107</span><span class="w">                       </span><span class="n">poplar</span><span class="o">::</span><span class="n">OptionFlags</span><span class="p">());</span>
<span class="linenos">108</span>
<span class="linenos">109</span><span class="w">    </span><span class="n">setOutTensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">);</span>
<span class="linenos">110</span><span class="w">  </span><span class="p">}</span>
<span class="linenos">111</span><span class="p">};</span>
<span class="linenos">112</span>
<span class="linenos">113</span><span class="k">static</span><span class="w"> </span><span class="n">popart</span><span class="o">::</span><span class="n">popx</span><span class="o">::</span><span class="n">OpxCreator</span><span class="o">&lt;</span><span class="n">LeakyReluOpx</span><span class="o">&gt;</span>
<span class="linenos">114</span><span class="w">    </span><span class="n">LeakyReluOpxCreator</span><span class="p">({</span><span class="n">CustomOperators</span><span class="o">::</span><span class="n">LeakyReluId</span><span class="p">});</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/5b83f74de987bbea1e40297fbcabc34a/leaky_relu_custom_op.cpp"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">leaky_relu_custom_op.cpp</span></code></a></p>
<p>Create a Makefile and generate <code class="docutils literal notranslate"><span class="pre">custom_ops.so</span></code> using the <code class="docutils literal notranslate"><span class="pre">make</span></code> command:</p>
<div class="literal-block-wrapper docutils container" id="makefile">
<div class="code-block-caption"><span class="caption-number">Listing 5.9 </span><span class="caption-text">Makefile</span><a class="headerlink" href="#makefile" title="Permalink to this code"></a></div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span>CXX ?= g++
<span class="linenos"> 2</span>CXXFLAGS = -std=c++14 -fPIC -g
<span class="linenos"> 3</span>LDLIBS = -shared -lpopart
<span class="linenos"> 4</span>ONNX_NAMESPACE = -DONNX_NAMESPACE=onnx
<span class="linenos"> 5</span>
<span class="linenos"> 6</span>BUILD_DIR = build
<span class="linenos"> 7</span>SOURCES = leaky_relu_custom_op.cpp
<span class="linenos"> 8</span>TARGET = $(BUILD_DIR)/custom_ops.so
<span class="linenos"> 9</span>
<span class="linenos">10</span>all: create_build_dir leaky_relu_custom_op
<span class="linenos">11</span>
<span class="linenos">12</span>.PHONY: create_build_dir
<span class="linenos">13</span>create_build_dir:
<span class="linenos">14</span>	mkdir -p $(BUILD_DIR)
<span class="linenos">15</span>
<span class="linenos">16</span>leaky_relu_custom_op: leaky_relu_custom_op.cpp
<span class="linenos">17</span>	$(CXX) $(SOURCES)  $(LDLIBS) $(CXXFLAGS) $(ONNX_NAMESPACE) -o $(TARGET)
<span class="linenos">18</span>
<span class="linenos">19</span>.PHONY: clean
<span class="linenos">20</span>clean:
<span class="linenos">21</span>	rm -rf  $(BUILD_DIR)
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/8f6b42dc65984e312d8337b50f511ed4/Makefile"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Makefile</span></code></a></p>
<p>Create a shape-inference file for the custom operator:</p>
<div class="literal-block-wrapper docutils container" id="custom-shape-inference-py">
<div class="code-block-caption"><span class="caption-number">Listing 5.10 </span><span class="caption-text">custom_shape_inference.py</span><a class="headerlink" href="#custom-shape-inference-py" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># Copyright (c) 2022 Graphcore Ltd. All rights reserved.</span>
<span class="linenos"> 2</span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>
<span class="linenos"> 3</span>
<span class="linenos"> 4</span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="linenos"> 5</span><span class="kn">import</span> <span class="nn">onnx.helper</span>
<span class="linenos"> 6</span><span class="kn">import</span> <span class="nn">onnx.shape_inference</span>
<span class="linenos"> 7</span>
<span class="linenos"> 8</span><span class="kn">from</span> <span class="nn">poprt.passes</span> <span class="kn">import</span> <span class="n">ShapeFunc</span><span class="p">,</span> <span class="n">get_dtype</span><span class="p">,</span> <span class="n">get_shape</span><span class="p">,</span> <span class="n">register_shape_func</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span>
<span class="linenos">11</span><span class="nd">@register_shape_func</span><span class="p">([</span><span class="s1">&#39;LeakyRelu&#39;</span><span class="p">])</span>
<span class="linenos">12</span><span class="k">class</span> <span class="nc">LeakyRelu</span><span class="p">(</span><span class="n">ShapeFunc</span><span class="p">):</span>
<span class="linenos">13</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Function based on ONNX to infer the shape and dtype of custom op.&quot;&quot;&quot;</span>
<span class="linenos">14</span>
<span class="linenos">15</span>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="linenos">16</span>        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
<span class="linenos">17</span>
<span class="linenos">18</span>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
<span class="linenos">19</span>        <span class="bp">self</span><span class="p">,</span>
<span class="linenos">20</span>        <span class="n">model</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span>
<span class="linenos">21</span>        <span class="n">node</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">NodeProto</span><span class="p">,</span>
<span class="linenos">22</span>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
<span class="linenos">23</span>        <span class="n">graph</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span>
<span class="linenos">24</span>        <span class="n">input_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos">25</span>        <span class="n">output_name</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="linenos">26</span>        <span class="c1"># If the Op already has known shape and dtype of output, return True</span>
<span class="linenos">27</span>        <span class="k">if</span> <span class="n">get_shape</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">output_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">get_dtype</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">output_name</span><span class="p">):</span>
<span class="linenos">28</span>            <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="kc">True</span>
<span class="linenos">29</span>
<span class="linenos">30</span>        <span class="n">input_dtype</span> <span class="o">=</span> <span class="n">get_dtype</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">input_name</span><span class="p">)</span>
<span class="linenos">31</span>        <span class="n">input_shape</span> <span class="o">=</span> <span class="n">get_shape</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">input_name</span><span class="p">)</span>
<span class="linenos">32</span>        <span class="c1"># If the Op is able to be inferred shape and dtype, return True</span>
<span class="linenos">33</span>        <span class="k">if</span> <span class="n">input_dtype</span> <span class="ow">and</span> <span class="n">input_shape</span> <span class="ow">and</span> <span class="mi">0</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="p">:</span>
<span class="linenos">34</span>            <span class="c1"># ![Shape-Inference Function begin]</span>
<span class="linenos">35</span>
<span class="linenos">36</span>            <span class="c1"># Step.1: Write the method following ONNX-Protobuf standard,</span>
<span class="linenos">37</span>            <span class="c1">#         to calc shape and dtype of output in terms of shape and dtype of input</span>
<span class="linenos">38</span>            <span class="c1"># The LeakyRelu Op has same shape and dtype with input and output</span>
<span class="linenos">39</span>
<span class="linenos">40</span>            <span class="c1"># Step.2: Create new TensorProto with inferred shape and dtype of output</span>
<span class="linenos">41</span>            <span class="n">output_tensor</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span>
<span class="linenos">42</span>                <span class="n">output_name</span><span class="p">,</span> <span class="n">input_dtype</span><span class="p">,</span> <span class="n">input_shape</span>
<span class="linenos">43</span>            <span class="p">)</span>
<span class="linenos">44</span>            <span class="c1"># Step.3: Call update_value_info to update</span>
<span class="linenos">45</span>            <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">update_value_info</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">output_tensor</span><span class="p">)</span>
<span class="linenos">46</span>            <span class="c1"># Step.4: Call infer_shapes function</span>
<span class="linenos">47</span>            <span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">shape_inference</span><span class="o">.</span><span class="n">infer_shapes</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="linenos">48</span>            <span class="c1"># ![Shape-Inference Function end]</span>
<span class="linenos">49</span>            <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="kc">True</span>
<span class="linenos">50</span>        <span class="c1"># If the Op is not able to be inferred, return False</span>
<span class="linenos">51</span>        <span class="k">else</span><span class="p">:</span>
<span class="linenos">52</span>            <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/054c40502ad2c786e6c5f455efcae0a1/custom_shape_inference.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">custom_shape_inference.py</span></code></a></p>
<section id="create-the-onnx-model-file-with-the-leakyrelu-op">
<h3>Create the ONNX model file with the <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> op<a class="headerlink" href="#create-the-onnx-model-file-with-the-leakyrelu-op" title="Permalink to this headline"></a></h3>
<p>Run the following test code with Python3 to generate the ONNX model file <code class="docutils literal notranslate"><span class="pre">custom_op_test.onnx</span></code> for testing:</p>
<div class="literal-block-wrapper docutils container" id="create-onnx-with-custom-op-py">
<div class="code-block-caption"><span class="caption-number">Listing 5.11 </span><span class="caption-text">create_onnx_with_custom_op.py</span><a class="headerlink" href="#create-onnx-with-custom-op-py" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># Copyright (c) 2022 Graphcore Ltd. All rights reserved.</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">os</span>
<span class="linenos"> 4</span>
<span class="linenos"> 5</span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="linenos"> 6</span>
<span class="linenos"> 7</span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">helper</span>
<span class="linenos"> 8</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span><span class="k">def</span> <span class="nf">create_onnx_model_with_custom_op</span><span class="p">():</span>
<span class="linenos">11</span>    <span class="n">TensorProto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span>
<span class="linenos">12</span>
<span class="linenos">13</span>    <span class="n">attributes</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;alpha&quot;</span><span class="p">:</span> <span class="mf">0.01</span><span class="p">}</span>
<span class="linenos">14</span>    <span class="n">leaky_relu</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span>
<span class="linenos">15</span>        <span class="s2">&quot;LeakyRelu&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;X&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="n">domain</span><span class="o">=</span><span class="s2">&quot;ai.graphcore&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">attributes</span>
<span class="linenos">16</span>    <span class="p">)</span>
<span class="linenos">17</span>    <span class="n">relu</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Relu&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Z&quot;</span><span class="p">])</span>
<span class="linenos">18</span>
<span class="linenos">19</span>    <span class="n">graph</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
<span class="linenos">20</span>        <span class="p">[</span><span class="n">leaky_relu</span><span class="p">,</span> <span class="n">relu</span><span class="p">],</span>
<span class="linenos">21</span>        <span class="s2">&quot;custom_op_test&quot;</span><span class="p">,</span>
<span class="linenos">22</span>        <span class="p">[</span>
<span class="linenos">23</span>            <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span>
<span class="linenos">24</span>        <span class="p">],</span>
<span class="linenos">25</span>        <span class="p">[</span>
<span class="linenos">26</span>            <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s2">&quot;Z&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)),</span>
<span class="linenos">27</span>        <span class="p">],</span>
<span class="linenos">28</span>    <span class="p">)</span>
<span class="linenos">29</span>    <span class="n">opset_imports</span> <span class="o">=</span> <span class="p">[</span><span class="n">helper</span><span class="o">.</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">11</span><span class="p">)]</span>
<span class="linenos">30</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">opset_imports</span><span class="o">=</span><span class="n">opset_imports</span><span class="p">)</span>
<span class="linenos">31</span>    <span class="n">model</span><span class="o">.</span><span class="n">opset_import</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">onnx</span><span class="o">.</span><span class="n">helper</span><span class="o">.</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;ai.graphcore&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="linenos">32</span>    <span class="k">return</span> <span class="n">model</span>
<span class="linenos">33</span>
<span class="linenos">34</span>
<span class="linenos">35</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="linenos">36</span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
<span class="linenos">37</span>        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Convert ONNX model and run it on the IPU.&#39;</span>
<span class="linenos">38</span>    <span class="p">)</span>
<span class="linenos">39</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos">40</span>        <span class="s1">&#39;--output_dir&#39;</span><span class="p">,</span>
<span class="linenos">41</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
<span class="linenos">42</span>        <span class="n">default</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">,</span>
<span class="linenos">43</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Full path of the directory the ONNX model will be saved to.&quot;</span><span class="p">,</span>
<span class="linenos">44</span>    <span class="p">)</span>
<span class="linenos">45</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="linenos">46</span>
<span class="linenos">47</span>    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">):</span>
<span class="linenos">48</span>        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;--output_dir should be an existing folder&quot;</span><span class="p">)</span>
<span class="linenos">49</span>
<span class="linenos">50</span>    <span class="n">model_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="s1">&#39;custom_op_test.onnx&#39;</span><span class="p">)</span>
<span class="linenos">51</span>
<span class="linenos">52</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">create_onnx_model_with_custom_op</span><span class="p">()</span>
<span class="linenos">53</span>    <span class="n">onnx</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_path</span><span class="p">)</span>
<span class="linenos">54</span>
<span class="linenos">55</span>    <span class="c1"># Convert and Run</span>
<span class="linenos">56</span>    <span class="n">compile_cmd</span> <span class="o">=</span> <span class="s2">&quot;bash build.sh&quot;</span>
<span class="linenos">57</span>    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">compile_cmd</span><span class="p">)</span>
<span class="linenos">58</span>    <span class="n">abs_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__file__</span><span class="p">))</span>
<span class="linenos">59</span>    <span class="n">run_cmd</span> <span class="o">=</span> <span class="sa">rf</span><span class="s2">&quot;&quot;&quot;poprt \</span>
<span class="linenos">60</span><span class="s2">--input_model </span><span class="si">{</span><span class="n">model_path</span><span class="si">}</span><span class="s2"> \</span>
<span class="linenos">61</span><span class="s2">--custom_shape_inference </span><span class="si">{</span><span class="n">abs_path</span><span class="si">}</span><span class="s2">/custom_shape_inference.py \</span>
<span class="linenos">62</span><span class="s2">--custom_library_so_paths </span><span class="si">{</span><span class="n">abs_path</span><span class="si">}</span><span class="s2">/custom_ops.so \</span>
<span class="linenos">63</span><span class="s2">--run&quot;&quot;&quot;</span>
<span class="linenos">64</span>    <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="n">run_cmd</span><span class="p">)</span>
<span class="linenos">65</span>    <span class="c1"># 2022-12-30 07:01:54,408 INFO cli.py:446] Bs: 8</span>
<span class="linenos">66</span>    <span class="c1"># 2022-12-30 07:01:54,408 INFO cli.py:449] Latency: 0.23ms</span>
<span class="linenos">67</span>    <span class="c1"># 2022-12-30 07:01:54,408 INFO cli.py:450] Tput: 35469</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/1c8c5c7916b5530e57ca2b299c3eb611/create_onnx_with_custom_op.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">create_onnx_with_custom_op.py</span></code></a></p>
</section>
</section>
<section id="using-custom-operators-in-poprt">
<h2><span class="section-number">5.8.2. </span>Using custom operators in PopRT<a class="headerlink" href="#using-custom-operators-in-poprt" title="Permalink to this headline"></a></h2>
<p>The library files of custom operators can be dynamically linked with the PopRT command line option <code class="docutils literal notranslate"><span class="pre">--custom_library_so_paths</span></code>, and the shape-inference for the custom operator can be registered with <code class="docutils literal notranslate"><span class="pre">--custom_shape_inference</span></code>.</p>
<p>The ONNX model file generated above can be executed with the following command:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">poprt \</span>
<span class="go">    --input_model custom_op_test.onnx \</span>
<span class="go">    --custom_library_so_paths custom_ops.so \</span>
<span class="go">    --custom_shape_inference custom_shape_inference.py \</span>
<span class="go">    --run</span>
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="model_fusion.html" class="btn btn-neutral float-left" title="5.7. Model fusion" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="custom_onnx_pass.html" class="btn btn-neutral float-right" title="5.9. Custom passes" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script id="hs-script-loader" async defer src="//js.hs-scripts.com/729091.js"></script>
    <script defer>
        if (typeof mutationObserver !== 'undefined')
            mutationObserver.observe(document.querySelector("div.rst-other-versions"), {childList: true, subtree: true})
        if (typeof updateDocumentLinks !== 'undefined')
            updateDocumentLinks()
        let search = document.querySelector("form#rtd-search-form > input[name='q']")
        if (document.location.pathname.startsWith("/projects/"))
          search.placeholder = "Search this document";
        else
          search.placeholder = "Search all documents";
    </script>


</body>
</html>