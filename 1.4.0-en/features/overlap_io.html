<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.3. Overlap I/O &mdash; Title</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/table_styling.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom_rtd.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/graphcore.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.4. Dynamic batch size" href="dynamic_batch_size.html" />
    <link rel="prev" title="5.2. FP8" href="fp8.html" />
     
    <script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1074732,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PX5BPGW');</script>
    <!-- End Google Tag Manager -->

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
  <a href="https://docs.graphcore.ai/" class="icon icon-home" title="Back to Documents Home"><img src="../_static/graphcorelogo-html.png" class="logo" alt="Logo"/></a>


<div class="homelink"><a href="../index.html">POPRT USER GUIDE</a></div>


  
  
    <div class="version">
      Version: 1.4.0
    </div>
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#background">1.1. Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#architecture">1.2. Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#workflow">1.3. Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">2. Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#compatibility-of-poprt-with-the-poplar-sdk">2.1. Compatibility of PopRT with the Poplar SDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-start-with-a-docker-image">2.2. Quick start with a Docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#install-poprt-on-host-server">2.3. Install PopRT on host server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#for-ubuntu-20-04">2.3.1. For Ubuntu 20.04</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poplar-sdk">Install Poplar SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#enable-the-sdk">Enable the SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poprt">Install PopRT</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">3. Quick start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#cli-parameters">3.1. CLI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#convert-and-run-model">3.2. Convert and run model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#download-onnx-model">3.2.1. Download ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#obtain-input-and-output-information-for-onnx-model">3.2.2. Obtain input and output information for ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-input-shape">3.2.3. Specify input shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-model-accuracy">3.2.4. Specify model accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-model">3.2.5. Run model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#export-popef-model">3.2.6. Export PopEF model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#quick-deployment">3.3. Quick deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-exported-popef-model">3.3.1. Run exported PopEF model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-converted-onnx-model">3.3.2. Run converted ONNX model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#python-api-example">3.4. Python API example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../instructions.html">4. Command line interface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Named Arguments">4.1. Named Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Sub-commands:">4.2. Sub-commands:</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../instructions.html#tf2onnx">4.2.1. tf2onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../instructions.html#Named Arguments_repeat1">Named Arguments</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">5. Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="passes.html">5.1. Passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="passes.html#pass-abstract">5.1.1. Pass abstract</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="fp8.html">5.2. FP8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#ipu-fp8-type">5.2.1. IPU FP8 type</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-quantisation">5.2.2. FP8 quantisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#converting-an-fp32-model-to-fp8">5.2.3. Converting an FP32 model to FP8</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-model-conversion-tool">5.2.4. FP8 model conversion tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#debugging-fp8-model-conversion-problems">5.2.5. Debugging FP8 model conversion problems</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.3. Overlap I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#principle">5.3.1. Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-i-o-tiles">5.3.2. Configuring I/O tiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="#debugging">5.3.3. Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="#concurrent-requests">5.3.4. Concurrent requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="#example">5.3.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dynamic_batch_size.html">5.4. Dynamic batch size</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#background">5.4.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#example">5.4.2. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="packing.html">5.5. Packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="packing.html#background">5.5.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#packing-and-unpacking">5.5.2. Packing and unpacking</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#transformer-based-nlp-models">5.5.3. Transformer-based NLP models</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#how-to-use-packing">5.5.4. How to use packing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="packing.html#downloading-the-model">Downloading the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#converting-the-model">Converting the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#running-the-model">Running the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpu_packing.html">5.6. CPU packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#background">5.6.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#functional-modules">5.6.2. Functional modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#timeout-processing">Timeout processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#user-data-preprocessing">User data preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#data-accumulation">Data accumulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#post-packing-processing">Post-packing processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#packing-algorithms">5.6.3. Packing algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#end-to-end-method">End-to-end method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#firstfit-method">FirstFit method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#nextfit-method">NextFit method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#examples">5.6.4. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_fusion.html">5.7. Model fusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-model-fusion">5.7.1. Implementing PopRT model fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-runtime-fusion-model-inference">5.7.2. Implementing PopRT Runtime fusion model inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_ops.html">5.8. Custom operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_ops.html#writing-custom-operators">5.8.1. Writing custom operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_ops.html#create-the-onnx-model-file-with-the-leakyrelu-op">Create the ONNX model file with the <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> op</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="custom_ops.html#using-custom-operators-in-poprt">5.8.2. Using custom operators in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_onnx_pass.html">5.9. Custom passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#implementing-custom-passes">5.9.1. Implementing custom passes</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes">5.9.2. Using custom passes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-poprt-cli">Using custom passes in the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-python-api">Using custom passes in the Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_pattern.html">5.10. Custom patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#implementing-custom-popart-patterns">5.10.1. Implementing custom PopART patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#using-custom-popart-patterns-in-poprt">5.10.2. Using custom PopART patterns in PopRT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-1-use-patterncreator-to-enable-the-pattern-by-default">Method 1: Use <code class="docutils literal notranslate"><span class="pre">PatternCreator</span></code> to enable the pattern by default</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-2-configure-a-pattern-using-the-python-api">Method 2: Configure a pattern using the Python API</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-3-config-the-specified-pattern-using-cli">Method 3: Config the specified pattern using CLI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_transform.html">5.11. Custom transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#implementing-custom-popart-transforms">5.11.1. Implementing custom PopART transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#using-custom-transforms-in-poprt">5.11.2. Using custom transforms in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="manual_sharding.html">5.12. Manual sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#sharding-and-model-parallelism">5.12.1. Sharding and model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#pipelining-and-pipeline-parallelism">5.12.2. Pipelining and pipeline parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#manual-sharding-process">5.12.3. Manual sharding process</a></li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding">5.12.4. Configuring manual sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding-with-the-poprt-cli">Configuring manual sharding with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="manual_sharding.html#configuring-manual-sharding-with-the-python-api">Configuring manual sharding with the Python API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="manual_sharding.html#example">5.12.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="error_handling.html">5.13. Error handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="frontend.html">5.14. PopRT frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#onnx-frontend">5.14.1. ONNX frontend</a></li>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#tensorflow-frontend">5.14.2. TensorFlow frontend</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-the-poprt-cli">Loading a TensorFlow model with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-python-api">Loading a TensorFlow model with Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto_sharding.html">5.15. Auto-sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#model-parallelism">5.15.1. Model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#principle-of-auto-sharding">5.15.2. Principle of auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#alternative-nodes-strategy">Alternative nodes strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#traversal-strategy-of-sharding-scheme">Traversal strategy of sharding scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#using-auto-sharding">5.15.3. Using auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#auto-sharding-tool">Auto-sharding tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_debugger.html">5.16. Model debugger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#model-debugger-tool">5.16.1. Model Debugger tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#examples">5.16.2. Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../python_api.html">6. Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-module">6.1. <code class="docutils literal notranslate"><span class="pre">poprt</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-compiler-module">6.2. <code class="docutils literal notranslate"><span class="pre">poprt.compiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-runtime-module">6.3. <code class="docutils literal notranslate"><span class="pre">poprt.runtime</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-frontend-module">6.4. <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-backends-module">6.5. <code class="docutils literal notranslate"><span class="pre">poprt.backends</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-quantizer-module">6.6. <code class="docutils literal notranslate"><span class="pre">poprt.quantizer</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-passes-module">6.7. <code class="docutils literal notranslate"><span class="pre">poprt.passes</span></code> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python_api.html#built-in-passes">6.7.1. Built-in passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cxx_api.html">7. C++ API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-compiler">7.1. PopRT Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#executable">7.2. Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-runtime">7.3. PopRT Runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cxx_api.html#devicemanager">7.3.1. DeviceManager</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../history.html">8. Revision history</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal.html">9. Trademarks &amp; copyright</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POPRT USER GUIDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="overlap-i-o">
<span id="features-overlap-io"></span><h1><span class="section-number">5.3. </span>Overlap I/O<a class="headerlink" href="#overlap-i-o" title="Permalink to this headline"></a></h1>
<p>The IPU execution of an inference model is generally divided into three stages:</p>
<ol class="arabic simple">
<li><p>Load: Copy input data from the host to the IPU</p></li>
<li><p>Compute: Model computing</p></li>
<li><p>Store: Copy result data from the IPU to the host</p></li>
</ol>
<p>These three stages are executed serially, which means that the computing resources of the IPU are idle while data is transferred in the Load and Store stages. In some models, with large input and output data, the performance of the whole model is limited by I/O. For this kind of model, enabling overlap I/O can overlap the computing stage and the I/O stage. This improves the utilisation rate of the computing resources of the IPU.</p>
<section id="principle">
<h2><span class="section-number">5.3.1. </span>Principle<a class="headerlink" href="#principle" title="Permalink to this headline"></a></h2>
<p>The principle of overlap I/O is to divide all the tiles on the IPU into two groups, namely compute tiles and I/O tiles. Compute tiles perform all computation, while I/O tiles only handle transferring data with the host. In this way, the stages of Load, Compute and Store form a three-level pipeline in a computational flow, which overlaps compute and I/O to improve the utilisation rate of the computing resources of the IPU.</p>
<figure class="align-center" id="fig-overlap-io">
<a class="reference internal image-reference" href="../_images/overlap_io_pipeline.png"><img alt="../_images/overlap_io_pipeline.png" src="../_images/overlap_io_pipeline.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5.2 </span><span class="caption-text">Pipeline formed by Load/Compute/Store</span><a class="headerlink" href="#fig-overlap-io" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="configuring-i-o-tiles">
<h2><span class="section-number">5.3.2. </span>Configuring I/O tiles<a class="headerlink" href="#configuring-i-o-tiles" title="Permalink to this headline"></a></h2>
<p>To enable overlap I/O, you only need to set one parameter, the number of I/O tiles. The number of I/O tiles can be adjusted to optimise the throughput of the transmission. To calculate the number of I/O tiles, you can divide the sum of the tensor sizes of all input and output by the SRAM size available for each tile and then round to the next power of 2.</p>
<ul class="simple">
<li><p>Configuring I/O tiles with the PopRT CLI <code class="docutils literal notranslate"><span class="pre">--num_io_tiles</span></code> parameter:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">poprt \</span>
<span class="go">    --input_model model.onnx \</span>
<span class="go">    --export_popef \</span>
<span class="go">    --output_dir model \</span>
<span class="go">    --num_io_tiles 128</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Configuring I/O tiles with the <a class="reference internal" href="../python_api.html#poprt.compiler.CompilerOptions" title="poprt.compiler.CompilerOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">poprt.compiler.CompilerOptions</span></code></a> API:</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">opts</span> <span class="o">=</span> <span class="n">poprt</span><span class="o">.</span><span class="n">compiler</span><span class="o">.</span><span class="n">CompilerOptions</span><span class="p">()</span>
<span class="n">opts</span><span class="o">.</span><span class="n">num_io_tiles</span> <span class="o">=</span> <span class="mi">128</span>
</pre></div>
</div>
</section>
<section id="debugging">
<h2><span class="section-number">5.3.3. </span>Debugging<a class="headerlink" href="#debugging" title="Permalink to this headline"></a></h2>
<p>You can use the <a class="reference external" href="https://docs.graphcore.ai/projects/graph-analyser-userguide/en/latest/index.html">PopVision Graph Analyser</a> to display the overlap between I/O and Compute stages to determine whether overlap I/O would improve your throughput. <a class="reference internal" href="#fig-popvision"><span class="std std-numref">Fig. 5.3</span></a> shows an example of the output of the PopVision Graph Analyser.</p>
<figure class="align-center" id="fig-popvision">
<a class="reference internal image-reference" href="../_images/overlap_io.png"><img alt="../_images/overlap_io.png" src="../_images/overlap_io.png" style="width: 90%;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5.3 </span><span class="caption-text">PopVision Graph Analyser shows overlap between I/O and Compute</span><a class="headerlink" href="#fig-popvision" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="concurrent-requests">
<h2><span class="section-number">5.3.4. </span>Concurrent requests<a class="headerlink" href="#concurrent-requests" title="Permalink to this headline"></a></h2>
<p>Since the three stages of inference form a three-stage pipeline through overlap I/O, sufficient concurrent data must be fed to the IPU in order to keep the pipeline full. At least three threads are required to feed the concurrent data to the IPU through the multi-threading mode.</p>
</section>
<section id="example">
<h2><span class="section-number">5.3.5. </span>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h2>
<p>The following is a simple example using overlap I/O:</p>
<div class="literal-block-wrapper docutils container" id="simple-overlapio-py">
<div class="code-block-caption"><span class="caption-number">Listing 5.1 </span><span class="caption-text">simple_overlapio.py</span><a class="headerlink" href="#simple-overlapio-py" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos">  1</span><span class="c1"># Copyright (c) 2022 Graphcore Ltd. All rights reserved.</span>
<span class="linenos">  2</span><span class="kn">import</span> <span class="nn">argparse</span>
<span class="linenos">  3</span><span class="kn">import</span> <span class="nn">threading</span>
<span class="linenos">  4</span>
<span class="linenos">  5</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos">  6</span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="linenos">  7</span>
<span class="linenos">  8</span><span class="kn">from</span> <span class="nn">onnx</span> <span class="kn">import</span> <span class="n">helper</span>
<span class="linenos">  9</span>
<span class="linenos"> 10</span><span class="kn">from</span> <span class="nn">poprt</span> <span class="kn">import</span> <span class="n">runtime</span>
<span class="linenos"> 11</span><span class="kn">from</span> <span class="nn">poprt.compiler</span> <span class="kn">import</span> <span class="n">Compiler</span><span class="p">,</span> <span class="n">CompilerOptions</span>
<span class="linenos"> 12</span><span class="kn">from</span> <span class="nn">poprt.runtime</span> <span class="kn">import</span> <span class="n">RuntimeConfig</span>
<span class="linenos"> 13</span>
<span class="linenos"> 14</span><span class="sd">&#39;&#39;&#39;</span>
<span class="linenos"> 15</span><span class="sd">PopRT use OverlapInnerLoop strategy as default exchange strategy.</span>
<span class="linenos"> 16</span><span class="sd">There are two loops in the main program: outer loop and inner loop.</span>
<span class="linenos"> 17</span><span class="sd">Each batch data needs to be processed in three pipeline stages: load/compute/store.</span>
<span class="linenos"> 18</span><span class="sd">Therefore, in order to enable the pipeline to run normally, at least three threads</span>
<span class="linenos"> 19</span><span class="sd">are required to feed data to the pipeline at the same time.</span>
<span class="linenos"> 20</span><span class="sd">==============================================================</span>
<span class="linenos"> 21</span><span class="sd">OverlapInnerLoop:</span>
<span class="linenos"> 22</span><span class="sd">- Boxes denote subgraphs / subgraph Ops / loops</span>
<span class="linenos"> 23</span><span class="sd">- Inputs/outputs are loop carried in order</span>
<span class="linenos"> 24</span>
<span class="linenos"> 25</span><span class="sd">.- outer loop ----------------------------------------.</span>
<span class="linenos"> 26</span><span class="sd">|                  .- inner loop -.                   |</span>
<span class="linenos"> 27</span><span class="sd">| load - compute - | - store      |                   |</span>
<span class="linenos"> 28</span><span class="sd">|           load - | - compute -- | - store           |</span>
<span class="linenos"> 29</span><span class="sd">|                  |   load ----- | - compute - store |</span>
<span class="linenos"> 30</span><span class="sd">|                  &#39;--------------&#39;                   |</span>
<span class="linenos"> 31</span><span class="sd">&#39;-----------------------------------------------------&#39;</span>
<span class="linenos"> 32</span><span class="sd">         ^^^^^^^       ^^^^^^^        ^^^^^^^</span>
<span class="linenos"> 33</span><span class="sd">         overlap       overlap        overlap</span>
<span class="linenos"> 34</span>
<span class="linenos"> 35</span><span class="sd">==============================================================</span>
<span class="linenos"> 36</span><span class="sd">&#39;&#39;&#39;</span>
<span class="linenos"> 37</span>
<span class="linenos"> 38</span>
<span class="linenos"> 39</span><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">onnx</span><span class="o">.</span><span class="n">ModelProto</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="linenos"> 40</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Compile ONNX to PopEF.&quot;&quot;&quot;</span>
<span class="linenos"> 41</span>    <span class="n">model_bytes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
<span class="linenos"> 42</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
<span class="linenos"> 43</span>
<span class="linenos"> 44</span>    <span class="n">options</span> <span class="o">=</span> <span class="n">CompilerOptions</span><span class="p">()</span>
<span class="hll"><span class="linenos"> 45</span>    <span class="n">options</span><span class="o">.</span><span class="n">batches_per_step</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">batches_per_step</span>
</span><span class="linenos"> 46</span>    <span class="n">options</span><span class="o">.</span><span class="n">num_io_tiles</span> <span class="o">=</span> <span class="n">args</span><span class="o">.</span><span class="n">num_io_tiles</span>
<span class="linenos"> 47</span>
<span class="linenos"> 48</span>    <span class="n">executable</span> <span class="o">=</span> <span class="n">Compiler</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model_bytes</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>
<span class="linenos"> 49</span>    <span class="k">return</span> <span class="n">executable</span>
<span class="linenos"> 50</span>
<span class="linenos"> 51</span>
<span class="linenos"> 52</span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">executable</span><span class="p">,</span> <span class="n">args</span><span class="p">):</span>
<span class="linenos"> 53</span><span class="w">    </span><span class="sd">&quot;&quot;&quot;Run PopEF.&quot;&quot;&quot;</span>
<span class="linenos"> 54</span>    <span class="c1"># Create model runner</span>
<span class="linenos"> 55</span>    <span class="n">config</span> <span class="o">=</span> <span class="n">RuntimeConfig</span><span class="p">()</span>
<span class="linenos"> 56</span>    <span class="n">config</span><span class="o">.</span><span class="n">timeout_ns</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos"> 57</span>    <span class="c1"># Create model runner</span>
<span class="linenos"> 58</span>    <span class="n">model_runner</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">Runner</span><span class="p">(</span><span class="n">executable</span><span class="p">,</span> <span class="n">config</span><span class="p">)</span>
<span class="linenos"> 59</span>
<span class="linenos"> 60</span>    <span class="n">inputs_info</span> <span class="o">=</span> <span class="n">model_runner</span><span class="o">.</span><span class="n">get_execute_inputs</span><span class="p">()</span>
<span class="linenos"> 61</span>    <span class="n">outputs_info</span> <span class="o">=</span> <span class="n">model_runner</span><span class="o">.</span><span class="n">get_execute_outputs</span><span class="p">()</span>
<span class="linenos"> 62</span>
<span class="linenos"> 63</span>    <span class="c1"># Run in multiple threads</span>
<span class="linenos"> 64</span>    <span class="k">def</span> <span class="nf">execute</span><span class="p">(</span><span class="n">bps</span><span class="p">,</span> <span class="n">inputs_info</span><span class="p">,</span> <span class="n">outputs_info</span><span class="p">):</span>
<span class="linenos"> 65</span>        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos"> 66</span>        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos"> 67</span>
<span class="linenos"> 68</span>        <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">inputs_info</span><span class="p">:</span>
<span class="linenos"> 69</span>            <span class="n">inputs</span><span class="p">[</span><span class="nb">input</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">input</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span>
<span class="linenos"> 70</span>                <span class="nb">input</span><span class="o">.</span><span class="n">numpy_data_type</span><span class="p">()</span>
<span class="linenos"> 71</span>            <span class="p">)</span>
<span class="linenos"> 72</span>        <span class="k">for</span> <span class="n">output</span> <span class="ow">in</span> <span class="n">outputs_info</span><span class="p">:</span>
<span class="linenos"> 73</span>            <span class="n">outputs</span><span class="p">[</span><span class="n">output</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span>
<span class="linenos"> 74</span>                <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="n">numpy_data_type</span><span class="p">()</span>
<span class="linenos"> 75</span>            <span class="p">)</span>
<span class="linenos"> 76</span>
<span class="linenos"> 77</span>        <span class="c1"># To correctly generate the popvision report, iteration must be a</span>
<span class="linenos"> 78</span>        <span class="c1"># multiple of batches_per_step and greater than 2 * batches_per_step</span>
<span class="linenos"> 79</span>        <span class="c1"># There are 3 threads, so the total number feed into IPU is 3 * iteration</span>
<span class="linenos"> 80</span>        <span class="n">iteration</span> <span class="o">=</span> <span class="n">bps</span>
<span class="hll"><span class="linenos"> 81</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
</span><span class="linenos"> 82</span>            <span class="n">model_runner</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="linenos"> 83</span>
<span class="linenos"> 84</span>    <span class="n">threads</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos"> 85</span>    <span class="n">num_threads</span> <span class="o">=</span> <span class="mi">3</span>
<span class="linenos"> 86</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Run PopEF with </span><span class="si">{</span><span class="n">num_threads</span><span class="si">}</span><span class="s2"> threads.&quot;</span><span class="p">)</span>
<span class="linenos"> 87</span>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_threads</span><span class="p">):</span>
<span class="linenos"> 88</span>        <span class="n">threads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<span class="linenos"> 89</span>            <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">(</span>
<span class="linenos"> 90</span>                <span class="n">target</span><span class="o">=</span><span class="n">execute</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">batches_per_step</span><span class="p">,</span> <span class="n">inputs_info</span><span class="p">,</span> <span class="n">outputs_info</span><span class="p">)</span>
<span class="linenos"> 91</span>            <span class="p">)</span>
<span class="linenos"> 92</span>        <span class="p">)</span>
<span class="linenos"> 93</span>
<span class="linenos"> 94</span>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">threads</span><span class="p">:</span>
<span class="linenos"> 95</span>        <span class="n">t</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
<span class="linenos"> 96</span>
<span class="linenos"> 97</span>    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">threads</span><span class="p">:</span>
<span class="linenos"> 98</span>        <span class="n">t</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
<span class="linenos"> 99</span>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Complete.&quot;</span><span class="p">)</span>
<span class="linenos">100</span>
<span class="linenos">101</span>
<span class="linenos">102</span><span class="k">def</span> <span class="nf">default_model</span><span class="p">():</span>
<span class="linenos">103</span>    <span class="n">TensorProto</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">TensorProto</span>
<span class="linenos">104</span>
<span class="linenos">105</span>    <span class="n">nodes</span> <span class="o">=</span> <span class="p">[]</span>
<span class="linenos">106</span>    <span class="n">num_matmuls</span> <span class="o">=</span> <span class="mi">4</span>
<span class="linenos">107</span>    <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;Expand&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="s2">&quot;shape&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;Act0&quot;</span><span class="p">]))</span>
<span class="linenos">108</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_matmuls</span><span class="p">):</span>
<span class="linenos">109</span>        <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;MatMul&quot;</span><span class="p">,</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Act</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;Weight&quot;</span><span class="p">],</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Act</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]))</span>
<span class="linenos">110</span>    <span class="n">nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
<span class="linenos">111</span>        <span class="n">helper</span><span class="o">.</span><span class="n">make_node</span><span class="p">(</span><span class="s2">&quot;ReduceMean&quot;</span><span class="p">,</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;Act</span><span class="si">{</span><span class="n">num_matmuls</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">],</span> <span class="p">[</span><span class="s2">&quot;output&quot;</span><span class="p">],</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="linenos">112</span>    <span class="p">)</span>
<span class="linenos">113</span>
<span class="linenos">114</span>    <span class="n">graph</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_graph</span><span class="p">(</span>
<span class="linenos">115</span>        <span class="n">nodes</span><span class="p">,</span>
<span class="linenos">116</span>        <span class="s2">&quot;matmul_test&quot;</span><span class="p">,</span>
<span class="linenos">117</span>        <span class="p">[</span>
<span class="linenos">118</span>            <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s2">&quot;input&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">)),</span>
<span class="linenos">119</span>        <span class="p">],</span>
<span class="linenos">120</span>        <span class="p">[</span><span class="n">helper</span><span class="o">.</span><span class="n">make_tensor_value_info</span><span class="p">(</span><span class="s2">&quot;output&quot;</span><span class="p">,</span> <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span> <span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">))],</span>
<span class="linenos">121</span>        <span class="p">[</span>
<span class="linenos">122</span>            <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span>
<span class="linenos">123</span>                <span class="s2">&quot;shape&quot;</span><span class="p">,</span>
<span class="linenos">124</span>                <span class="n">TensorProto</span><span class="o">.</span><span class="n">INT64</span><span class="p">,</span>
<span class="linenos">125</span>                <span class="p">[</span><span class="mi">4</span><span class="p">],</span>
<span class="linenos">126</span>                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
<span class="linenos">127</span>            <span class="p">),</span>
<span class="linenos">128</span>            <span class="n">helper</span><span class="o">.</span><span class="n">make_tensor</span><span class="p">(</span>
<span class="linenos">129</span>                <span class="s2">&quot;Weight&quot;</span><span class="p">,</span>
<span class="linenos">130</span>                <span class="n">TensorProto</span><span class="o">.</span><span class="n">FLOAT</span><span class="p">,</span>
<span class="linenos">131</span>                <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<span class="linenos">132</span>                <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
<span class="linenos">133</span>            <span class="p">),</span>
<span class="linenos">134</span>        <span class="p">],</span>
<span class="linenos">135</span>    <span class="p">)</span>
<span class="linenos">136</span>    <span class="n">opset_imports</span> <span class="o">=</span> <span class="p">[</span><span class="n">helper</span><span class="o">.</span><span class="n">make_opsetid</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="mi">11</span><span class="p">)]</span>
<span class="linenos">137</span>    <span class="n">original_model</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">make_model</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">opset_imports</span><span class="o">=</span><span class="n">opset_imports</span><span class="p">)</span>
<span class="linenos">138</span>    <span class="k">return</span> <span class="n">original_model</span>
<span class="linenos">139</span>
<span class="linenos">140</span>
<span class="linenos">141</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="linenos">142</span>    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span>
<span class="linenos">143</span>        <span class="n">description</span><span class="o">=</span><span class="s1">&#39;Convert onnx model and run it on IPU.&#39;</span>
<span class="linenos">144</span>    <span class="p">)</span>
<span class="linenos">145</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos">146</span>        <span class="s1">&#39;--batches_per_step&#39;</span><span class="p">,</span>
<span class="linenos">147</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos">148</span>        <span class="n">default</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<span class="linenos">149</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of on-chip loop count.&quot;</span><span class="p">,</span>
<span class="linenos">150</span>    <span class="p">)</span>
<span class="linenos">151</span>    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
<span class="linenos">152</span>        <span class="s1">&#39;--num_io_tiles&#39;</span><span class="p">,</span>
<span class="linenos">153</span>        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
<span class="linenos">154</span>        <span class="n">default</span><span class="o">=</span><span class="mi">192</span><span class="p">,</span>
<span class="linenos">155</span>        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;The number of IO tiles.&quot;</span><span class="p">,</span>
<span class="linenos">156</span>    <span class="p">)</span>
<span class="linenos">157</span>    <span class="n">args</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>
<span class="linenos">158</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">default_model</span><span class="p">()</span>
<span class="linenos">159</span>    <span class="n">exec</span> <span class="o">=</span> <span class="nb">compile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
<span class="linenos">160</span>    <span class="n">run</span><span class="p">(</span><span class="n">exec</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/e6afb4c5146650575d21976eff1092c7/simple_overlapio.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">simple_overlapio.py</span></code></a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="fp8.html" class="btn btn-neutral float-left" title="5.2. FP8" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="dynamic_batch_size.html" class="btn btn-neutral float-right" title="5.4. Dynamic batch size" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script id="hs-script-loader" async defer src="//js.hs-scripts.com/729091.js"></script>
    <script defer>
        if (typeof mutationObserver !== 'undefined')
            mutationObserver.observe(document.querySelector("div.rst-other-versions"), {childList: true, subtree: true})
        if (typeof updateDocumentLinks !== 'undefined')
            updateDocumentLinks()
        let search = document.querySelector("form#rtd-search-form > input[name='q']")
        if (document.location.pathname.startsWith("/projects/"))
          search.placeholder = "Search this document";
        else
          search.placeholder = "Search all documents";
    </script>


</body>
</html>