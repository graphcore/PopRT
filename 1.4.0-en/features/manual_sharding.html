<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>5.12. Manual sharding &mdash; Title</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="../_static/table_styling.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom_rtd.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/js/graphcore.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="5.13. Error handling" href="error_handling.html" />
    <link rel="prev" title="5.11. Custom transforms" href="custom_transform.html" />
     
    <script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1074732,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PX5BPGW');</script>
    <!-- End Google Tag Manager -->

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
  <a href="https://docs.graphcore.ai/" class="icon icon-home" title="Back to Documents Home"><img src="../_static/graphcorelogo-html.png" class="logo" alt="Logo"/></a>


<div class="homelink"><a href="../index.html">POPRT USER GUIDE</a></div>


  
  
    <div class="version">
      Version: 1.4.0
    </div>
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#background">1.1. Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#architecture">1.2. Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="../overview.html#workflow">1.3. Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">2. Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#compatibility-of-poprt-with-the-poplar-sdk">2.1. Compatibility of PopRT with the Poplar SDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#quick-start-with-a-docker-image">2.2. Quick start with a Docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="../installation.html#install-poprt-on-host-server">2.3. Install PopRT on host server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../installation.html#for-ubuntu-20-04">2.3.1. For Ubuntu 20.04</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poplar-sdk">Install Poplar SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#enable-the-sdk">Enable the SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="../installation.html#install-poprt">Install PopRT</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../quick_start.html">3. Quick start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#cli-parameters">3.1. CLI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#convert-and-run-model">3.2. Convert and run model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#download-onnx-model">3.2.1. Download ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#obtain-input-and-output-information-for-onnx-model">3.2.2. Obtain input and output information for ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-input-shape">3.2.3. Specify input shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#specify-model-accuracy">3.2.4. Specify model accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-model">3.2.5. Run model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#export-popef-model">3.2.6. Export PopEF model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#quick-deployment">3.3. Quick deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-exported-popef-model">3.3.1. Run exported PopEF model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../quick_start.html#run-converted-onnx-model">3.3.2. Run converted ONNX model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../quick_start.html#python-api-example">3.4. Python API example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../instructions.html">4. Command line interface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Named Arguments">4.1. Named Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../instructions.html#Sub-commands:">4.2. Sub-commands:</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../instructions.html#tf2onnx">4.2.1. tf2onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../instructions.html#Named Arguments_repeat1">Named Arguments</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">5. Features</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="passes.html">5.1. Passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="passes.html#pass-abstract">5.1.1. Pass abstract</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="fp8.html">5.2. FP8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#ipu-fp8-type">5.2.1. IPU FP8 type</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-quantisation">5.2.2. FP8 quantisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#converting-an-fp32-model-to-fp8">5.2.3. Converting an FP32 model to FP8</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#fp8-model-conversion-tool">5.2.4. FP8 model conversion tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="fp8.html#debugging-fp8-model-conversion-problems">5.2.5. Debugging FP8 model conversion problems</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="overlap_io.html">5.3. Overlap I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#principle">5.3.1. Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#configuring-i-o-tiles">5.3.2. Configuring I/O tiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#debugging">5.3.3. Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#concurrent-requests">5.3.4. Concurrent requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="overlap_io.html#example">5.3.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="dynamic_batch_size.html">5.4. Dynamic batch size</a><ul>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#background">5.4.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="dynamic_batch_size.html#example">5.4.2. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="packing.html">5.5. Packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="packing.html#background">5.5.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#packing-and-unpacking">5.5.2. Packing and unpacking</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#transformer-based-nlp-models">5.5.3. Transformer-based NLP models</a></li>
<li class="toctree-l3"><a class="reference internal" href="packing.html#how-to-use-packing">5.5.4. How to use packing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="packing.html#downloading-the-model">Downloading the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#converting-the-model">Converting the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="packing.html#running-the-model">Running the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="cpu_packing.html">5.6. CPU packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#background">5.6.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#functional-modules">5.6.2. Functional modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#timeout-processing">Timeout processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#user-data-preprocessing">User data preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#data-accumulation">Data accumulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#post-packing-processing">Post-packing processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#packing-algorithms">5.6.3. Packing algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#end-to-end-method">End-to-end method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#firstfit-method">FirstFit method</a></li>
<li class="toctree-l4"><a class="reference internal" href="cpu_packing.html#nextfit-method">NextFit method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="cpu_packing.html#examples">5.6.4. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_fusion.html">5.7. Model fusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-model-fusion">5.7.1. Implementing PopRT model fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_fusion.html#implementing-poprt-runtime-fusion-model-inference">5.7.2. Implementing PopRT Runtime fusion model inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_ops.html">5.8. Custom operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_ops.html#writing-custom-operators">5.8.1. Writing custom operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_ops.html#create-the-onnx-model-file-with-the-leakyrelu-op">Create the ONNX model file with the <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> op</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="custom_ops.html#using-custom-operators-in-poprt">5.8.2. Using custom operators in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_onnx_pass.html">5.9. Custom passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#implementing-custom-passes">5.9.1. Implementing custom passes</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes">5.9.2. Using custom passes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-poprt-cli">Using custom passes in the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_onnx_pass.html#using-custom-passes-in-the-python-api">Using custom passes in the Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_pattern.html">5.10. Custom patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#implementing-custom-popart-patterns">5.10.1. Implementing custom PopART patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_pattern.html#using-custom-popart-patterns-in-poprt">5.10.2. Using custom PopART patterns in PopRT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-1-use-patterncreator-to-enable-the-pattern-by-default">Method 1: Use <code class="docutils literal notranslate"><span class="pre">PatternCreator</span></code> to enable the pattern by default</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-2-configure-a-pattern-using-the-python-api">Method 2: Configure a pattern using the Python API</a></li>
<li class="toctree-l4"><a class="reference internal" href="custom_pattern.html#method-3-config-the-specified-pattern-using-cli">Method 3: Config the specified pattern using CLI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="custom_transform.html">5.11. Custom transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#implementing-custom-popart-transforms">5.11.1. Implementing custom PopART transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="custom_transform.html#using-custom-transforms-in-poprt">5.11.2. Using custom transforms in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">5.12. Manual sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#sharding-and-model-parallelism">5.12.1. Sharding and model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#pipelining-and-pipeline-parallelism">5.12.2. Pipelining and pipeline parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="#manual-sharding-process">5.12.3. Manual sharding process</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuring-manual-sharding">5.12.4. Configuring manual sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#configuring-manual-sharding-with-the-poprt-cli">Configuring manual sharding with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="#configuring-manual-sharding-with-the-python-api">Configuring manual sharding with the Python API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#example">5.12.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="error_handling.html">5.13. Error handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="frontend.html">5.14. PopRT frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#onnx-frontend">5.14.1. ONNX frontend</a></li>
<li class="toctree-l3"><a class="reference internal" href="frontend.html#tensorflow-frontend">5.14.2. TensorFlow frontend</a><ul>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-the-poprt-cli">Loading a TensorFlow model with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="frontend.html#loading-a-tensorflow-model-with-python-api">Loading a TensorFlow model with Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="auto_sharding.html">5.15. Auto-sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#model-parallelism">5.15.1. Model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#principle-of-auto-sharding">5.15.2. Principle of auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#alternative-nodes-strategy">Alternative nodes strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#traversal-strategy-of-sharding-scheme">Traversal strategy of sharding scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="auto_sharding.html#using-auto-sharding">5.15.3. Using auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#auto-sharding-tool">Auto-sharding tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="auto_sharding.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="model_debugger.html">5.16. Model debugger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#model-debugger-tool">5.16.1. Model Debugger tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="model_debugger.html#examples">5.16.2. Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../python_api.html">6. Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-module">6.1. <code class="docutils literal notranslate"><span class="pre">poprt</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-compiler-module">6.2. <code class="docutils literal notranslate"><span class="pre">poprt.compiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-runtime-module">6.3. <code class="docutils literal notranslate"><span class="pre">poprt.runtime</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-frontend-module">6.4. <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-backends-module">6.5. <code class="docutils literal notranslate"><span class="pre">poprt.backends</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-quantizer-module">6.6. <code class="docutils literal notranslate"><span class="pre">poprt.quantizer</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../python_api.html#poprt-passes-module">6.7. <code class="docutils literal notranslate"><span class="pre">poprt.passes</span></code> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../python_api.html#built-in-passes">6.7.1. Built-in passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cxx_api.html">7. C++ API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-compiler">7.1. PopRT Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#executable">7.2. Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cxx_api.html#poprt-runtime">7.3. PopRT Runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../cxx_api.html#devicemanager">7.3.1. DeviceManager</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../history.html">8. Revision history</a></li>
<li class="toctree-l1"><a class="reference internal" href="../legal.html">9. Trademarks &amp; copyright</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">POPRT USER GUIDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="manual-sharding">
<span id="features-manual-sharding"></span><h1><span class="section-number">5.12. </span>Manual sharding<a class="headerlink" href="#manual-sharding" title="Permalink to this headline"></a></h1>
<p>PopRT manual sharding supports dividing the model into different subgraphs through sharding points provided by users to achieve model parallelism and pipeline parallelism.</p>
<section id="sharding-and-model-parallelism">
<h2><span class="section-number">5.12.1. </span>Sharding and model parallelism<a class="headerlink" href="#sharding-and-model-parallelism" title="Permalink to this headline"></a></h2>
<p>PopRT supports sharding the ONNX graph across different devices based on the sharding points provided by users to achieve model parallelism. Sharding is suitable for large models that exceed the memory limit of a single device and require multiple devices.</p>
<p>For more information, refer to the section on sharding in the <a class="reference external" href="https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/sharding.html">technical note</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use model parallelism, the PopRT backend options need to be set as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">options.virtual_graph_mode</span></code> = “manual”</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">options.num_ipus</span></code> = number of devices</p></li>
</ul>
</div>
</section>
<section id="pipelining-and-pipeline-parallelism">
<h2><span class="section-number">5.12.2. </span>Pipelining and pipeline parallelism<a class="headerlink" href="#pipelining-and-pipeline-parallelism" title="Permalink to this headline"></a></h2>
<p>PopRT supports sharding the ONNX graph across different pipeline stages based on the sharding points provided by users to achieve pipeline parallelism and improve throughput.</p>
<p>For more information, refer to the sections on pipelining <a class="reference external" href="https://docs.graphcore.ai/projects/tf-model-parallelism/en/latest/pipelining.html">in the technical note</a> and in the <a class="reference external" href="https://docs.graphcore.ai/projects/ipu-programmers-guide/en/latest/algorithmic_techniques.html#model-parallelism-and-pipelining">IPU Programmer’s Guide</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To use pipeline parallelism, it is necessary to enable model parallelism and set the PopRT backend options as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">options.enable_pipelining</span></code> = True</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">options.batches_per_step</span></code> = integer multiple of the number of pipeline stages</p></li>
</ul>
</div>
</section>
<section id="manual-sharding-process">
<h2><span class="section-number">5.12.3. </span>Manual sharding process<a class="headerlink" href="#manual-sharding-process" title="Permalink to this headline"></a></h2>
<p>PopRT manual sharding shards the ONNX graph based on the ONNX node, and the sharding point can be any ONNX node.</p>
<ol class="arabic">
<li><p>The nodes in the ONNX graph are arranged in topological sorting order. PopRT manual sharding first performs topological sorting of the sharding points set by the user.</p></li>
<li><p>Traverse the sharding point. Take the sharding point as the starting point to traverse the ONNX graph in the direction of input, and put all the traversed ONNX nodes into a subgraph. If there is no input node or the node has already set sharding information, then stop the traversal of such branch.</p></li>
<li><p>After the traversal is completed, you will get the subgraph. Set the sharding information of the subgraph using ONNX attribute:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__ipu_number</span></code> specifies the device serial number corresponding to each subgraph in model parallelism</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__pipeline_stage</span></code> specifies the pipeline stage corresponding to each subgraph in pipeline parallelism.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li><p>Different sharding points can have the same device serial number and pipeline stage. For example, if there are two parallel branches started from different sharding points, and we want to put them onto a single device, then these two sharding points will have same device serial number.</p></li>
<li><p>After the sharding information is set based on the sharding point, the remaining nodes without sharding information are automatically set:</p>
<blockquote>
<div><ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__ipu_number</span></code> will be set to the currently set maximum device serial number +1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__pipeline_stage</span></code> will be set to the currently set maximum pipeline stage +1.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div>
</section>
<section id="configuring-manual-sharding">
<h2><span class="section-number">5.12.4. </span>Configuring manual sharding<a class="headerlink" href="#configuring-manual-sharding" title="Permalink to this headline"></a></h2>
<p>There are two methods for configuring manual sharding:</p>
<ul class="simple">
<li><p>with the PopRT CLI</p></li>
<li><p>with the <code class="xref py py-class docutils literal notranslate"><span class="pre">poprt.converter.Sharder</span></code> class.</p></li>
</ul>
<section id="configuring-manual-sharding-with-the-poprt-cli">
<h3>Configuring manual sharding with the PopRT CLI<a class="headerlink" href="#configuring-manual-sharding-with-the-poprt-cli" title="Permalink to this headline"></a></h3>
<ul class="simple">
<li><p>Specify the sharding point name, device serial number and pipeline stage with the yaml file:</p></li>
</ul>
<div class="literal-block-wrapper docutils container" id="shard-yaml">
<div class="code-block-caption"><span class="caption-number">Listing 5.17 </span><span class="caption-text">shard.yaml</span><a class="headerlink" href="#shard-yaml" title="Permalink to this code"></a></div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="p p-Indicator">-</span>
<span class="linenos"> 2</span><span class="w">  </span><span class="nt">node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">resnetv17_stage1__plus0</span>
<span class="linenos"> 3</span><span class="w">  </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos"> 4</span><span class="w">  </span><span class="nt">stage</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="linenos"> 5</span><span class="p p-Indicator">-</span>
<span class="linenos"> 6</span><span class="w">  </span><span class="nt">node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">resnetv17_stage4_batchnorm2_fwd</span>
<span class="linenos"> 7</span><span class="w">  </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos"> 8</span><span class="w">  </span><span class="nt">stage</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="linenos"> 9</span><span class="p p-Indicator">-</span>
<span class="linenos">10</span><span class="w">  </span><span class="nt">node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">resnetv17_stage4__plus0</span>
<span class="linenos">11</span><span class="w">  </span><span class="nt">device</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="linenos">12</span><span class="w">  </span><span class="nt">stage</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/2001c3516846b5aaa7e1f5f92ae3526e/shard.yaml"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">shard.yaml</span></code></a></p>
<ul class="simple">
<li><p>Configuring sharding information with <code class="docutils literal notranslate"><span class="pre">--manual_sharding_config</span></code> in the PopRT CLI:</p></li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">poprt \</span>
<span class="go">    --input_model model.onnx \</span>
<span class="go">    --manual_sharding_config shard.yaml</span>
</pre></div>
</div>
<ul>
<li><p>Determine whether to perform manual sharding only on <code class="docutils literal notranslate"><span class="pre">input_model</span></code> with <code class="docutils literal notranslate"><span class="pre">--only_manual_sharding</span></code> in the PopRT CLI, which is not set by default.</p>
<blockquote>
<div><p>Not setting <code class="docutils literal notranslate"><span class="pre">--only_manual_sharding</span></code> means that manual sharding is performed after the Convert phase optimisation on <code class="docutils literal notranslate"><span class="pre">input_model</span></code>.</p>
<p>Setting <code class="docutils literal notranslate"><span class="pre">--only_manual_sharding</span></code> means that only manual sharding is performed on <code class="docutils literal notranslate"><span class="pre">input_model</span></code>. Only <code class="docutils literal notranslate"><span class="pre">--input_model</span></code>, <code class="docutils literal notranslate"><span class="pre">--output_model</span></code>, <code class="docutils literal notranslate"><span class="pre">--output_dir</span></code> and <code class="docutils literal notranslate"><span class="pre">--manual_sharding_config</span></code> are supported; other parameters are invalid.</p>
</div></blockquote>
</li>
</ul>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">poprt \</span>
<span class="go">    --input_model model.onnx \</span>
<span class="go">    --manual_sharding_config shard.yaml \</span>
<span class="go">    --only_manual_sharding</span>
</pre></div>
</div>
</section>
<section id="configuring-manual-sharding-with-the-python-api">
<h3>Configuring manual sharding with the Python API<a class="headerlink" href="#configuring-manual-sharding-with-the-python-api" title="Permalink to this headline"></a></h3>
<p>You can use <code class="xref py py-class docutils literal notranslate"><span class="pre">poprt.converter.Sharder</span></code> to configure manual sharding.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">sharding_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;resnetv17_stage1__plus0&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;resnetv17_stage4_batchnorm2_fwd&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;resnetv17_stage4__plus0: 2,</span>
<span class="p">}</span>
<span class="n">pipelining_info</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;resnetv17_stage1__plus0&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s2">&quot;resnetv17_stage4_batchnorm2_fwd&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s2">&quot;resnetv17_stage4__plus0: 2,</span>
<span class="p">}</span>

<span class="n">sharded_model</span> <span class="o">=</span> <span class="n">poprt</span><span class="o">.</span><span class="n">converter</span><span class="o">.</span><span class="n">Sharder</span><span class="p">(</span>
                            <span class="n">sharding_info</span><span class="o">=</span><span class="n">sharding_info</span><span class="p">,</span>
                            <span class="n">pipelining_info</span><span class="o">=</span><span class="n">pipelining_info</span>
                        <span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">converted_model</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The PopRT CLI with <code class="docutils literal notranslate"><span class="pre">--only_manual_sharding</span></code> set or the use of <code class="xref py py-class docutils literal notranslate"><span class="pre">poprt.converter.Sharder</span></code> API needs to guarantee that every node in the ONNX graph has <code class="docutils literal notranslate"><span class="pre">unique</span> <span class="pre">name</span></code>.</p></li>
<li><p>The PopRT CLI without <code class="docutils literal notranslate"><span class="pre">--only_manual_sharding</span></code> set does not need to guarantee that every node in the ONNX graph has <code class="docutils literal notranslate"><span class="pre">unique</span> <span class="pre">name</span></code>. The Convert optimisation process will guarantee that every node has <code class="docutils literal notranslate"><span class="pre">unique</span> <span class="pre">name</span></code>.</p></li>
</ul>
</div>
</section>
</section>
<section id="example">
<h2><span class="section-number">5.12.5. </span>Example<a class="headerlink" href="#example" title="Permalink to this headline"></a></h2>
<p>The following is a simple example of manual sharding:</p>
<p>Take <a class="reference external" href="https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v1-7.onnx">ResNet50</a> as an example.</p>
<div class="literal-block-wrapper docutils container" id="shard-py">
<div class="code-block-caption"><span class="caption-number">Listing 5.18 </span><span class="caption-text">shard.py</span><a class="headerlink" href="#shard-py" title="Permalink to this code"></a></div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="linenos"> 1</span><span class="c1"># Copyright (c) 2023 Graphcore Ltd. All rights reserved.</span>
<span class="linenos"> 2</span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="linenos"> 3</span><span class="kn">import</span> <span class="nn">onnx</span>
<span class="linenos"> 4</span><span class="kn">import</span> <span class="nn">requests</span>
<span class="linenos"> 5</span>
<span class="linenos"> 6</span><span class="kn">from</span> <span class="nn">poprt</span> <span class="kn">import</span> <span class="n">runtime</span>
<span class="linenos"> 7</span><span class="kn">from</span> <span class="nn">poprt.compiler</span> <span class="kn">import</span> <span class="n">Compiler</span><span class="p">,</span> <span class="n">CompilerOptions</span>
<span class="linenos"> 8</span><span class="kn">from</span> <span class="nn">poprt.converter</span> <span class="kn">import</span> <span class="n">Sharder</span>
<span class="linenos"> 9</span>
<span class="linenos">10</span>
<span class="linenos">11</span><span class="k">def</span> <span class="nf">load_model</span><span class="p">():</span>
<span class="linenos">12</span>    <span class="c1"># Download model</span>
<span class="linenos">13</span>    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/onnx/models/raw/main/vision/classification/resnet/model/resnet50-v1-7.onnx&#39;</span>
<span class="linenos">14</span>    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="linenos">15</span>    <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">200</span><span class="p">:</span>
<span class="linenos">16</span>        <span class="n">model</span> <span class="o">=</span> <span class="n">onnx</span><span class="o">.</span><span class="n">load_model_from_string</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="linenos">17</span>    <span class="k">else</span><span class="p">:</span>
<span class="linenos">18</span>        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span>
<span class="linenos">19</span>            <span class="sa">f</span><span class="s2">&quot;Failed to download model with status_code </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="linenos">20</span>        <span class="p">)</span>
<span class="linenos">21</span>    <span class="k">return</span> <span class="n">model</span>
<span class="linenos">22</span>
<span class="linenos">23</span>
<span class="linenos">24</span><span class="k">def</span> <span class="nf">manual_sharding</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="linenos">25</span>    <span class="c1"># Fix the batch size to 1</span>
<span class="linenos">26</span>    <span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">input</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">type</span><span class="o">.</span><span class="n">tensor_type</span><span class="o">.</span><span class="n">shape</span><span class="o">.</span><span class="n">dim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dim_value</span> <span class="o">=</span> <span class="mi">1</span>
<span class="linenos">27</span>
<span class="linenos">28</span>    <span class="c1"># Sharding and pipelining info</span>
<span class="linenos">29</span>    <span class="n">sharding_info</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">30</span>        <span class="s2">&quot;resnetv17_stage1__plus0&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="linenos">31</span>        <span class="s2">&quot;resnetv17_stage4_batchnorm2_fwd&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">32</span>        <span class="s2">&quot;resnetv17_stage4__plus0&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">33</span>    <span class="p">}</span>
<span class="linenos">34</span>    <span class="n">pipelining_info</span> <span class="o">=</span> <span class="p">{</span>
<span class="linenos">35</span>        <span class="s2">&quot;resnetv17_stage1__plus0&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="linenos">36</span>        <span class="s2">&quot;resnetv17_stage4_batchnorm2_fwd&quot;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
<span class="linenos">37</span>        <span class="s2">&quot;resnetv17_stage4__plus0&quot;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
<span class="linenos">38</span>    <span class="p">}</span>
<span class="linenos">39</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">Sharder</span><span class="p">(</span><span class="n">sharding_info</span><span class="o">=</span><span class="n">sharding_info</span><span class="p">,</span> <span class="n">pipelining_info</span><span class="o">=</span><span class="n">pipelining_info</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
<span class="linenos">40</span>        <span class="n">model</span>
<span class="linenos">41</span>    <span class="p">)</span>
<span class="linenos">42</span>
<span class="linenos">43</span>    <span class="k">return</span> <span class="n">model</span>
<span class="linenos">44</span>
<span class="linenos">45</span>
<span class="linenos">46</span><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span class="linenos">47</span>    <span class="c1"># Compile the model with backend options</span>
<span class="linenos">48</span>    <span class="n">model_bytes</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">()</span>
<span class="linenos">49</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">output</span><span class="p">]</span>
<span class="linenos">50</span>
<span class="linenos">51</span>    <span class="n">options</span> <span class="o">=</span> <span class="n">CompilerOptions</span><span class="p">()</span>
<span class="linenos">52</span>    <span class="n">options</span><span class="o">.</span><span class="n">ipu_version</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">DeviceManager</span><span class="p">()</span><span class="o">.</span><span class="n">ipu_hardware_version</span><span class="p">()</span>
<span class="linenos">53</span>    <span class="c1"># Sharding into 4 IPUs</span>
<span class="linenos">54</span>    <span class="n">options</span><span class="o">.</span><span class="n">num_ipus</span> <span class="o">=</span> <span class="mi">4</span>
<span class="linenos">55</span>    <span class="c1"># Enable Sharding and Pipelining</span>
<span class="linenos">56</span>    <span class="n">options</span><span class="o">.</span><span class="n">enable_pipelining</span> <span class="o">=</span> <span class="kc">True</span>
<span class="linenos">57</span>    <span class="n">options</span><span class="o">.</span><span class="n">virtual_graph_mode</span> <span class="o">=</span> <span class="s2">&quot;manual&quot;</span>
<span class="linenos">58</span>    <span class="n">options</span><span class="o">.</span><span class="n">batches_per_step</span> <span class="o">=</span> <span class="mi">16</span>
<span class="linenos">59</span>
<span class="linenos">60</span>    <span class="n">executable</span> <span class="o">=</span> <span class="n">Compiler</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model_bytes</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">options</span><span class="p">)</span>
<span class="linenos">61</span>    <span class="n">runner_config</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">RuntimeConfig</span><span class="p">()</span>
<span class="linenos">62</span>    <span class="n">runner_config</span><span class="o">.</span><span class="n">timeout_ns</span> <span class="o">=</span> <span class="mi">0</span>
<span class="linenos">63</span>    <span class="n">runner</span> <span class="o">=</span> <span class="n">runtime</span><span class="o">.</span><span class="n">Runner</span><span class="p">(</span><span class="n">executable</span><span class="p">,</span> <span class="n">runner_config</span><span class="p">)</span>
<span class="linenos">64</span>    <span class="k">return</span> <span class="n">runner</span>
<span class="linenos">65</span>
<span class="linenos">66</span>
<span class="linenos">67</span><span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="n">runner</span><span class="p">):</span>
<span class="linenos">68</span>    <span class="n">inputs_info</span> <span class="o">=</span> <span class="n">runner</span><span class="o">.</span><span class="n">get_execute_inputs</span><span class="p">()</span>
<span class="linenos">69</span>    <span class="n">outputs_info</span> <span class="o">=</span> <span class="n">runner</span><span class="o">.</span><span class="n">get_execute_outputs</span><span class="p">()</span>
<span class="linenos">70</span>
<span class="linenos">71</span>    <span class="n">inputs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos">72</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">inputs_info</span><span class="p">:</span>
<span class="linenos">73</span>        <span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">i</span><span class="o">.</span><span class="n">numpy_data_type</span><span class="p">())</span>
<span class="linenos">74</span>
<span class="linenos">75</span>    <span class="n">outputs</span> <span class="o">=</span> <span class="p">{}</span>
<span class="linenos">76</span>    <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">outputs_info</span><span class="p">:</span>
<span class="linenos">77</span>        <span class="n">outputs</span><span class="p">[</span><span class="n">o</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">o</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">o</span><span class="o">.</span><span class="n">numpy_data_type</span><span class="p">())</span>
<span class="linenos">78</span>
<span class="linenos">79</span>    <span class="n">runner</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>
<span class="linenos">80</span>
<span class="linenos">81</span>
<span class="linenos">82</span><span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
<span class="linenos">83</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">()</span>
<span class="linenos">84</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">manual_sharding</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="linenos">85</span>    <span class="n">runner</span> <span class="o">=</span> <span class="nb">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="linenos">86</span>    <span class="n">run</span><span class="p">(</span><span class="n">runner</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p><a class="reference download internal" download="" href="../_downloads/07db38d22f485231fce9dfa46fd4d943/shard.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">shard.py</span></code></a></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="custom_transform.html" class="btn btn-neutral float-left" title="5.11. Custom transforms" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="error_handling.html" class="btn btn-neutral float-right" title="5.13. Error handling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script id="hs-script-loader" async defer src="//js.hs-scripts.com/729091.js"></script>
    <script defer>
        if (typeof mutationObserver !== 'undefined')
            mutationObserver.observe(document.querySelector("div.rst-other-versions"), {childList: true, subtree: true})
        if (typeof updateDocumentLinks !== 'undefined')
            updateDocumentLinks()
        let search = document.querySelector("form#rtd-search-form > input[name='q']")
        if (document.location.pathname.startsWith("/projects/"))
          search.placeholder = "Search this document";
        else
          search.placeholder = "Search all documents";
    </script>


</body>
</html>