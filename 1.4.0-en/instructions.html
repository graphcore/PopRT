<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>4. Command line interface &mdash; Title</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="_static/tabs.css" type="text/css" />
      <link rel="stylesheet" href="_static/table_styling.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/custom_rtd.css" type="text/css" />
    <link rel="shortcut icon" href="_static/favicon.png"/>
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/clipboard.min.js"></script>
        <script src="_static/copybutton.js"></script>
        <script src="_static/js/graphcore.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. Features" href="features/index.html" />
    <link rel="prev" title="3. Quick start" href="quick_start.html" />
     
    <script>
    (function(h,o,t,j,a,r){
        h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
        h._hjSettings={hjid:1074732,hjsv:6};
        a=o.getElementsByTagName('head')[0];
        r=o.createElement('script');r.async=1;
        r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
        a.appendChild(r);
    })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
    </script>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-PX5BPGW');</script>
    <!-- End Google Tag Manager -->

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

  
  <a href="https://docs.graphcore.ai/" class="icon icon-home" title="Back to Documents Home"><img src="_static/graphcorelogo-html.png" class="logo" alt="Logo"/></a>


<div class="homelink"><a href="index.html">POPRT USER GUIDE</a></div>


  
  
    <div class="version">
      Version: 1.4.0
    </div>
  



<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">1. Introduction</a><ul>
<li class="toctree-l2"><a class="reference internal" href="overview.html#background">1.1. Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#architecture">1.2. Architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="overview.html#workflow">1.3. Workflow</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">2. Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#compatibility-of-poprt-with-the-poplar-sdk">2.1. Compatibility of PopRT with the Poplar SDK</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#quick-start-with-a-docker-image">2.2. Quick start with a Docker image</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#install-poprt-on-host-server">2.3. Install PopRT on host server</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#for-ubuntu-20-04">2.3.1. For Ubuntu 20.04</a><ul>
<li class="toctree-l4"><a class="reference internal" href="installation.html#install-poplar-sdk">Install Poplar SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="installation.html#enable-the-sdk">Enable the SDK</a></li>
<li class="toctree-l4"><a class="reference internal" href="installation.html#install-poprt">Install PopRT</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">3. Quick start</a><ul>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#cli-parameters">3.1. CLI parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#convert-and-run-model">3.2. Convert and run model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#download-onnx-model">3.2.1. Download ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#obtain-input-and-output-information-for-onnx-model">3.2.2. Obtain input and output information for ONNX model</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#specify-input-shape">3.2.3. Specify input shape</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#specify-model-accuracy">3.2.4. Specify model accuracy</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#run-model">3.2.5. Run model</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#export-popef-model">3.2.6. Export PopEF model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#quick-deployment">3.3. Quick deployment</a><ul>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#run-exported-popef-model">3.3.1. Run exported PopEF model</a></li>
<li class="toctree-l3"><a class="reference internal" href="quick_start.html#run-converted-onnx-model">3.3.2. Run converted ONNX model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="quick_start.html#python-api-example">3.4. Python API example</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. Command line interface</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Named Arguments">4.1. Named Arguments</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Sub-commands:">4.2. Sub-commands:</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#tf2onnx">4.2.1. tf2onnx</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#Named Arguments_repeat1">Named Arguments</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="features/index.html">5. Features</a><ul>
<li class="toctree-l2"><a class="reference internal" href="features/passes.html">5.1. Passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/passes.html#pass-abstract">5.1.1. Pass abstract</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/fp8.html">5.2. FP8</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#ipu-fp8-type">5.2.1. IPU FP8 type</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#fp8-quantisation">5.2.2. FP8 quantisation</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#converting-an-fp32-model-to-fp8">5.2.3. Converting an FP32 model to FP8</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#fp8-model-conversion-tool">5.2.4. FP8 model conversion tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/fp8.html#debugging-fp8-model-conversion-problems">5.2.5. Debugging FP8 model conversion problems</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/overlap_io.html">5.3. Overlap I/O</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#principle">5.3.1. Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#configuring-i-o-tiles">5.3.2. Configuring I/O tiles</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#debugging">5.3.3. Debugging</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#concurrent-requests">5.3.4. Concurrent requests</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/overlap_io.html#example">5.3.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/dynamic_batch_size.html">5.4. Dynamic batch size</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/dynamic_batch_size.html#background">5.4.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/dynamic_batch_size.html#example">5.4.2. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/packing.html">5.5. Packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#background">5.5.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#packing-and-unpacking">5.5.2. Packing and unpacking</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#transformer-based-nlp-models">5.5.3. Transformer-based NLP models</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/packing.html#how-to-use-packing">5.5.4. How to use packing</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#downloading-the-model">Downloading the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#converting-the-model">Converting the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/packing.html#running-the-model">Running the model</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/cpu_packing.html">5.6. CPU packing</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#background">5.6.1. Background</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#functional-modules">5.6.2. Functional modules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#timeout-processing">Timeout processing</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#user-data-preprocessing">User data preprocessing</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#data-accumulation">Data accumulation</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#post-packing-processing">Post-packing processing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#packing-algorithms">5.6.3. Packing algorithms</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#end-to-end-method">End-to-end method</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#firstfit-method">FirstFit method</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/cpu_packing.html#nextfit-method">NextFit method</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/cpu_packing.html#examples">5.6.4. Examples</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/model_fusion.html">5.7. Model fusion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/model_fusion.html#implementing-poprt-model-fusion">5.7.1. Implementing PopRT model fusion</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/model_fusion.html#implementing-poprt-runtime-fusion-model-inference">5.7.2. Implementing PopRT Runtime fusion model inference</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_ops.html">5.8. Custom operations</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_ops.html#writing-custom-operators">5.8.1. Writing custom operators</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_ops.html#create-the-onnx-model-file-with-the-leakyrelu-op">Create the ONNX model file with the <code class="docutils literal notranslate"><span class="pre">LeakyRelu</span></code> op</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_ops.html#using-custom-operators-in-poprt">5.8.2. Using custom operators in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_onnx_pass.html">5.9. Custom passes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_onnx_pass.html#implementing-custom-passes">5.9.1. Implementing custom passes</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_onnx_pass.html#using-custom-passes">5.9.2. Using custom passes</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_onnx_pass.html#using-custom-passes-in-the-poprt-cli">Using custom passes in the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_onnx_pass.html#using-custom-passes-in-the-python-api">Using custom passes in the Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_pattern.html">5.10. Custom patterns</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_pattern.html#implementing-custom-popart-patterns">5.10.1. Implementing custom PopART patterns</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_pattern.html#using-custom-popart-patterns-in-poprt">5.10.2. Using custom PopART patterns in PopRT</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#method-1-use-patterncreator-to-enable-the-pattern-by-default">Method 1: Use <code class="docutils literal notranslate"><span class="pre">PatternCreator</span></code> to enable the pattern by default</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#method-2-configure-a-pattern-using-the-python-api">Method 2: Configure a pattern using the Python API</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/custom_pattern.html#method-3-config-the-specified-pattern-using-cli">Method 3: Config the specified pattern using CLI</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/custom_transform.html">5.11. Custom transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/custom_transform.html#implementing-custom-popart-transforms">5.11.1. Implementing custom PopART transforms</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/custom_transform.html#using-custom-transforms-in-poprt">5.11.2. Using custom transforms in PopRT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/manual_sharding.html">5.12. Manual sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#sharding-and-model-parallelism">5.12.1. Sharding and model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#pipelining-and-pipeline-parallelism">5.12.2. Pipelining and pipeline parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#manual-sharding-process">5.12.3. Manual sharding process</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#configuring-manual-sharding">5.12.4. Configuring manual sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/manual_sharding.html#configuring-manual-sharding-with-the-poprt-cli">Configuring manual sharding with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/manual_sharding.html#configuring-manual-sharding-with-the-python-api">Configuring manual sharding with the Python API</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/manual_sharding.html#example">5.12.5. Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/error_handling.html">5.13. Error handling</a></li>
<li class="toctree-l2"><a class="reference internal" href="features/frontend.html">5.14. PopRT frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/frontend.html#onnx-frontend">5.14.1. ONNX frontend</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/frontend.html#tensorflow-frontend">5.14.2. TensorFlow frontend</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/frontend.html#loading-a-tensorflow-model-with-the-poprt-cli">Loading a TensorFlow model with the PopRT CLI</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/frontend.html#loading-a-tensorflow-model-with-python-api">Loading a TensorFlow model with Python API</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/auto_sharding.html">5.15. Auto-sharding</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#model-parallelism">5.15.1. Model parallelism</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#principle-of-auto-sharding">5.15.2. Principle of auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#alternative-nodes-strategy">Alternative nodes strategy</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#traversal-strategy-of-sharding-scheme">Traversal strategy of sharding scheme</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="features/auto_sharding.html#using-auto-sharding">5.15.3. Using auto-sharding</a><ul>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#auto-sharding-tool">Auto-sharding tool</a></li>
<li class="toctree-l4"><a class="reference internal" href="features/auto_sharding.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="features/model_debugger.html">5.16. Model debugger</a><ul>
<li class="toctree-l3"><a class="reference internal" href="features/model_debugger.html#model-debugger-tool">5.16.1. Model Debugger tool</a></li>
<li class="toctree-l3"><a class="reference internal" href="features/model_debugger.html#examples">5.16.2. Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python_api.html">6. Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-module">6.1. <code class="docutils literal notranslate"><span class="pre">poprt</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-compiler-module">6.2. <code class="docutils literal notranslate"><span class="pre">poprt.compiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-runtime-module">6.3. <code class="docutils literal notranslate"><span class="pre">poprt.runtime</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-frontend-module">6.4. <code class="docutils literal notranslate"><span class="pre">poprt.frontend</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-backends-module">6.5. <code class="docutils literal notranslate"><span class="pre">poprt.backends</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-quantizer-module">6.6. <code class="docutils literal notranslate"><span class="pre">poprt.quantizer</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#poprt-passes-module">6.7. <code class="docutils literal notranslate"><span class="pre">poprt.passes</span></code> module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="python_api.html#built-in-passes">6.7.1. Built-in passes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cxx_api.html">7. C++ API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#poprt-compiler">7.1. PopRT Compiler</a></li>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#executable">7.2. Executable</a></li>
<li class="toctree-l2"><a class="reference internal" href="cxx_api.html#poprt-runtime">7.3. PopRT Runtime</a><ul>
<li class="toctree-l3"><a class="reference internal" href="cxx_api.html#devicemanager">7.3.1. DeviceManager</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="history.html">8. Revision history</a></li>
<li class="toctree-l1"><a class="reference internal" href="legal.html">9. Trademarks &amp; copyright</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">POPRT USER GUIDE</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="command-line-interface">
<span id="instructions"></span><h1><span class="section-number">4. </span>Command line interface<a class="headerlink" href="#command-line-interface" title="Permalink to this headline"></a></h1>
<p><p>poprt is a tool to help quickly deploy ONNX models on IPUs.</p>
</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">poprt</span>
       <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">available_memory_proportion</span> <span class="n">AVAILABLE_MEMORY_PROPORTION</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batch_size</span> <span class="n">BATCH_SIZE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batch_axis</span> <span class="n">BATCH_AXIS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">batches_per_step</span> <span class="n">BATCHES_PER_STEP</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">calibration_with_data</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">calibration_loss_type</span> <span class="p">{</span><span class="n">mse</span><span class="p">,</span><span class="n">mae</span><span class="p">,</span><span class="n">snr</span><span class="p">,</span><span class="n">kld</span><span class="p">,</span><span class="n">cos_dist</span><span class="p">,</span><span class="n">gptq</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">check</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">checkpoints</span> <span class="n">CHECKPOINTS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">compiler_options</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">config_yaml</span> <span class="n">CONFIG_YAML</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">convert_version</span> <span class="n">CONVERT_VERSION</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_library_so_paths</span> <span class="n">CUSTOM_LIBRARY_SO_PATHS</span> <span class="p">[</span><span class="n">CUSTOM_LIBRARY_SO_PATHS</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_pass_config</span> <span class="n">CUSTOM_PASS_CONFIG</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">custom_shape_inference</span> <span class="n">CUSTOM_SHAPE_INFERENCE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">data_preprocess</span> <span class="n">DATA_PREPROCESS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">disable_compilation_progress_bar</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">disable_fast_norm</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">eightbitsio</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_if_with_same_cond</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_compress_pattern</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_erf_gelu</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_insert_remap</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">export_popef</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fold_periodic_initializer</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp16_skip_op_types</span> <span class="n">FP16_SKIP_OP_TYPES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">enable_avoid_overflow_patterns</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp8_skip_op_names</span> <span class="n">FP8_SKIP_OP_NAMES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">fp8_params</span> <span class="n">FP8_PARAMS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">framework</span> <span class="n">FRAMEWORK</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">infer_shape_ahead</span><span class="p">]</span>
       <span class="p">[</span><span class="o">-</span><span class="n">i</span> <span class="n">INPUT_MODEL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">input_shape</span> <span class="n">INPUT_TENSOR_NAME</span> <span class="o">=</span> <span class="n">INPUT_SHAPE</span> <span class="p">[</span><span class="n">INPUT_TENSOR_NAME</span> <span class="o">=</span> <span class="n">INPUT_SHAPE</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">ipu_version</span> <span class="p">{</span><span class="n">ipu2</span><span class="p">,</span><span class="n">ipu21</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">list_all_passes</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">logging_level</span> <span class="p">{</span><span class="n">DEBUG</span><span class="p">,</span><span class="n">INFO</span><span class="p">,</span><span class="n">WARNING</span><span class="p">,</span><span class="n">ERROR</span><span class="p">,</span><span class="n">CRITICAL</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">manual_sharding_config</span> <span class="n">MANUAL_SHARDING_CONFIG</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">max_tensor_size</span> <span class="n">MAX_TENSOR_SIZE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">num_io_tiles</span> <span class="n">NUM_IO_TILES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">num_of_layers_keep_fp16</span> <span class="n">NUM_OF_LAYERS_KEEP_FP16</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">only_manual_sharding</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">optimize_internal_exchange_code</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">output_dir</span> <span class="n">OUTPUT_DIR</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">output_model</span> <span class="n">OUTPUT_MODEL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">pack_args</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">passes</span> <span class="n">PASSES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">perf_tuner</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">popart_options</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">precision</span> <span class="p">{</span><span class="n">fp32</span><span class="p">,</span><span class="n">fp16</span><span class="p">,</span><span class="n">fp8</span><span class="p">,</span><span class="n">fp8_weight</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">precision_compare</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">print_completion</span> <span class="p">{</span><span class="n">bash</span><span class="p">,</span><span class="n">zsh</span><span class="p">}]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">remap_mode</span> <span class="n">REMAP_MODE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">remove_outputs</span> <span class="n">REMOVE_OUTPUTS</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">run</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">serialize_matmul</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">serialize_matmul_add</span> <span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="p">[</span><span class="n">KEY</span><span class="o">=</span><span class="n">VAL</span> <span class="o">...</span><span class="p">]]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_matmul</span> <span class="n">MERGE_MATMUL</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_matmul_add</span> <span class="n">MERGE_MATMUL_ADD</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">merge_moe</span> <span class="n">MERGE_MOE</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">show</span><span class="p">]</span>
       <span class="p">[</span><span class="o">--</span><span class="n">skip_passes</span> <span class="n">SKIP_PASSES</span><span class="p">]</span>
       <span class="p">[</span><span class="o">-</span><span class="n">v</span><span class="p">]</span>
       <span class="p">{</span><span class="n">tf2onnx</span><span class="p">}</span>
       <span class="o">...</span>
</pre></div>
</div>
<section id="Named Arguments">
<h2><span class="section-number">4.1. </span>Named Arguments<a class="headerlink" href="#Named Arguments" title="Permalink to this headline"></a></h2>
<dl class="option-list">
<dt><kbd>--available_memory_proportion</kbd></dt>
<dd><p>Set the available memory proportion for MatMul, Conv and Gemm Ops. Range (0, 1]. Default None.</p>
</dd>
<dt><kbd>--batch_size</kbd></dt>
<dd><p>Set the batch size for all inputs. Works with the batch_axis parameter.</p>
</dd>
<dt><kbd>--batch_axis</kbd></dt>
<dd><p>Specify the batch axis for all inputs. Works with the batch_size parameter.</p>
</dd>
<dt><kbd>--batches_per_step</kbd></dt>
<dd><p>Set the number of mini-batches to perform on the device before returning to the host. Default: 1.</p>
<p>Default: 1</p>
</dd>
<dt><kbd>--calibration_with_data</kbd></dt>
<dd><p>Calibrate the FP8 model using the calibration data. Note that this option only applies when precisionis set to fp8 or fp8_weight.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--calibration_loss_type</kbd></dt>
<dd><p>Possible choices: mse, mae, snr, kld, cos_dist, gptq</p>
<p>Choose the calibration method, note that gptq can only be used for calibration of fp8_weight. Default is kld.</p>
<p>Default: “kld”</p>
</dd>
<dt><kbd>--check</kbd></dt>
<dd><p>Use made-up data to check that the model runs.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--checkpoints</kbd></dt>
<dd><p>Add intermediate tensor into outputs of graph in order to debug the precision. Default None.</p>
</dd>
<dt><kbd>--compiler_options</kbd></dt>
<dd><p>Set PopRT Compiler Options.</p>
</dd>
<dt><kbd>--config_yaml</kbd></dt>
<dd><p>Set the path of the yaml config file. Default None.</p>
</dd>
<dt><kbd>--convert_version</kbd></dt>
<dd><p>Convert the opset version of ONNX model to CONVERT_VERSION. Default 11.</p>
<p>Default: 11</p>
</dd>
<dt><kbd>--custom_library_so_paths</kbd></dt>
<dd><p>Paths of the custom shared library with custom ops/patterns/transforms.</p>
</dd>
<dt><kbd>--custom_pass_config</kbd></dt>
<dd><p>Path of the custom pass config file.</p>
</dd>
<dt><kbd>--custom_shape_inference</kbd></dt>
<dd><p>Paths of the custom shape inference scripts.For example: <cite>–custom_shape_inference “./custom_shape_inference_1.py,../ops/custom_shape_inference_2.py”</cite>.</p>
</dd>
<dt><kbd>--data_preprocess</kbd></dt>
<dd><p>Path of pickle format file for data preprocessing.</p>
</dd>
<dt><kbd>--disable_compilation_progress_bar</kbd></dt>
<dd><p>Do not show compilation progress bar.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--disable_fast_norm</kbd></dt>
<dd><p>Do not transfer layer_norm Ops to fast_norm Ops.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--eightbitsio</kbd></dt>
<dd><p>Enable 8-bit input/output.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--merge_if_with_same_cond</kbd></dt>
<dd><p>enable merge of if Ops that use the same conditional input.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_compress_pattern</kbd></dt>
<dd><p>Enable replace Compress patterns with MaskCompress Ops.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_erf_gelu</kbd></dt>
<dd><p>Enable replace Erf Gelu patterns with Gelu op.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--enable_insert_remap</kbd></dt>
<dd><p>Enable insert remap automatically to improve tensor layout.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--export_popef</kbd></dt>
<dd><p>Enable the generation of PopEF model files in the conversion process.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fold_periodic_initializer</kbd></dt>
<dd><p>Fold periodic initializer to save Always-Live memory.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fp16_skip_op_types</kbd></dt>
<dd><p>Set the list of op types which will keep <cite>float32</cite> operands in <cite>float16</cite> mode. Default None.</p>
</dd>
<dt><kbd>--enable_avoid_overflow_patterns</kbd></dt>
<dd><p>Enable to keep <cite>float32</cite> for several specific patterns in a <cite>float16</cite> model.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--fp8_skip_op_names</kbd></dt>
<dd><p>The names of ops which will remain as <cite>float32</cite> or <cite>float16</cite> in <cite>fp8</cite> mode. For example, “Conv_1, Conv_2”. Default None</p>
</dd>
<dt><kbd>--fp8_params</kbd></dt>
<dd><p>Set parameters to fp8 model, the format is “input_format,weight_format,input_scale,weight_scale”</p>
<p>Default: “F143,F143,-1,-1”</p>
</dd>
<dt><kbd>--framework</kbd></dt>
<dd><p>Specify frontend to load input model.</p>
<p>Default: “onnx”</p>
</dd>
<dt><kbd>--infer_shape_ahead</kbd></dt>
<dd><p>Fix input shape and infer shapes at beginning.</p>
<p>Default: False</p>
</dd>
<dt><kbd>-i, --input_model</kbd></dt>
<dd><p>Set the path of the original ONNX model.</p>
</dd>
<dt><kbd>--input_shape</kbd></dt>
<dd><p>Set the input shape of the model. If the model input is variable, we recommend setting the model input shape. For example: <cite>–input_shape input_ids=1,512 attention_mask=1,512</cite>.</p>
</dd>
<dt><kbd>--ipu_version</kbd></dt>
<dd><p>Possible choices: ipu2, ipu21</p>
<p>Set the IPU version: use ipu21 for C600 systems and ipu2 for IPU-M2000 and Bow-2000 systems. Default ipu2.</p>
<p>Default: “ipu2”</p>
</dd>
<dt><kbd>--list_all_passes</kbd></dt>
<dd><p>List all passes. Refer to <cite>–passes</cite>.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--logging_level</kbd></dt>
<dd><p>Possible choices: DEBUG, INFO, WARNING, ERROR, CRITICAL</p>
<p>Set the logging level. Default WARNING.</p>
<p>Default: “WARNING”</p>
</dd>
<dt><kbd>--manual_sharding_config</kbd></dt>
<dd><p>Set the path of the yaml config file of sharding and pipelining. Default None.</p>
</dd>
<dt><kbd>--max_tensor_size</kbd></dt>
<dd><p>Set max tensor size(bytes) generated by constant_folding. -1 means do not set max_tensor_size by default.For example: <cite>–max_tensor_size 41943040</cite> means constant_folding can only generate tensors smaller than 40MB.</p>
<p>Default: -1</p>
</dd>
<dt><kbd>--num_io_tiles</kbd></dt>
<dd><p>Set the number of IPU tiles dedicated to IO. Default 0. IPU run in OverlapIO mode if this number &gt; 0. For more information about OverlapIO see the PopART user guide: <a class="reference external" href="https://docs.graphcore.ai/projects/popart-user-guide/en/latest/overlap_io.html">https://docs.graphcore.ai/projects/popart-user-guide/en/latest/overlap_io.html</a>.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--num_of_layers_keep_fp16</kbd></dt>
<dd><p>Set the layer whose loss is topk to fp16 in fp8 quantization.</p>
<p>Default: 0</p>
</dd>
<dt><kbd>--only_manual_sharding</kbd></dt>
<dd><p>Only shard the graph in the cli. If enable only_manual_sharding, the cli only supports <cite>–input_model</cite>, <cite>–output_model</cite>, <cite>–output_dir</cite> and <cite>–manual_sharding_config</cite>. <cite>–output_model</cite> and <a href="#id1"><span class="problematic" id="id2">`</span></a>–output_dir are optional.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--optimize_internal_exchange_code</kbd></dt>
<dd><p>Enable to optimize the memory usage of internal exchange code.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--output_dir</kbd></dt>
<dd><p>Set the output directory where the converted model files and PopEF files are saved. Default current directory.</p>
<p>Default: “./”</p>
</dd>
<dt><kbd>--output_model</kbd></dt>
<dd><p>Set the name of the converted ONNX model. This will be placed in the <cite>–output_dir</cite> directory.</p>
</dd>
<dt><kbd>--pack_args</kbd></dt>
<dd><p>Set the pack args, for example: –pack_args max_valid_num=50 enable_double_batch_unpack=false segment_max_size=13+51</p>
</dd>
<dt><kbd>--passes</kbd></dt>
<dd><p>Set the passes to be used during conversion. Default None. For example: <cite>–passes “pre_scale,fuse_attention”</cite>.  Refer to <cite>–list_all_passes</cite> which is able to show all available passes.</p>
</dd>
<dt><kbd>--perf_tuner</kbd></dt>
<dd><p>Enable the performance tuner, unimplemented now.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--popart_options</kbd></dt>
<dd><p>Set PopART Session Options. For more information: <a class="reference external" href="https://docs.graphcore.ai/projects/popart-python-api/en/latest/api-python.html?highlight=POPART#session-options">https://docs.graphcore.ai/projects/popart-python-api/en/latest/api-python.html?highlight=POPART#session-options</a>.</p>
</dd>
<dt><kbd>--precision</kbd></dt>
<dd><p>Possible choices: fp32, fp16, fp8, fp8_weight</p>
<p>Quantize the model to the specfied precision. Default fp32.</p>
<p>Default: “fp32”</p>
</dd>
<dt><kbd>--precision_compare</kbd></dt>
<dd><p>Compare the output precision of conv/matmul/gemm between the origin and the converted model,note that it only take effect when precision is set to fp8 or fp8_weight</p>
<p>Default: False</p>
</dd>
<dt><kbd>--print_completion</kbd></dt>
<dd><p>Possible choices: bash, zsh</p>
<p>print shell completion script.</p>
</dd>
<dt><kbd>--remap_mode</kbd></dt>
<dd><p>Set the insert position of remap, valid only if enable_insert_remap is set.Must be templated with ‘before/after’+’_’+’op_type’(such as after_matmul,before_softmax,after_concat).</p>
<p>Default: “after_matmul”</p>
</dd>
<dt><kbd>--remove_outputs</kbd></dt>
<dd><p>Remove the specific outputs and useless structures from the graph.</p>
</dd>
<dt><kbd>--run</kbd></dt>
<dd><p>Run PopEF with random data.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--serialize_matmul</kbd></dt>
<dd><p>Enable to serialize MatMul op to save memory on chip. –serialize_matmul ${OP_NAME}=${FACTOR}/${MODE}/${KEEP_PRECISION} or –serialize_matmul ${OP_NAME}=${FACTOR}/${MODE} or –serialize_matmul ${OP_NAME}=${FACTOR}. ${MODE} choices [ input_channels, output_channels, reducing_dim, none ]. Default is output_channels. ${KEEP_PRECISION} choices [ True, False ]. Default is False. For example, –serialize_matmul MatMul_1=4/input_channels/True MatMul_2=4/input_channels MatMul_3=4</p>
</dd>
<dt><kbd>--serialize_matmul_add</kbd></dt>
<dd><p>Enable to serialize MatMul weights and Add bias with weights last dim to save memory on chip. –serialize_matmul_add ${MATMUL_OP_NAME}/${ADD_OP_NAME}=${FACTOR} For example, –serialize_matmul_add MatMul_1/Add_2=4</p>
</dd>
<dt><kbd>--merge_matmul</kbd></dt>
<dd><p>Enable to merge MatMul operations to save cycles. –merge_matmul ${MATMUL_OP_NAME1},${MATMUL_OP_NAME2} For example, –merge_matmul MatMul_1,MatMul_2</p>
</dd>
<dt><kbd>--merge_matmul_add</kbd></dt>
<dd><p>Enable to merge MatMul/Add operations to save cycles. –merge_matmul_add ${MATMUL_OP_NAME1},${ADD_OP_NAME1},${MATMUL_OP_NAME2},${ADD_OP_NAME2} For example, –merge_matmul_add MatMul_1,Add_1,MatMul_2,Add_2</p>
</dd>
<dt><kbd>--merge_moe</kbd></dt>
<dd><p>Enable to merge Mixture-of-Experts structure to save cycles. –merge_moe ${EXPERT_BEGIN_OP_NAME1},${EXPERT_END_OP_NAME1},${EXPERT_BEGIN_OP_NAME2},${EXPERT_END_OP_NAME2} For example, –merge_moe MatMul_1,Add_1,MatMul_2,Add_2</p>
</dd>
<dt><kbd>--show</kbd></dt>
<dd><p>Show the input and output information of the model.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--skip_passes</kbd></dt>
<dd><p>Set the list of passes that will be skipped. Default None.</p>
</dd>
<dt><kbd>-v, --version</kbd></dt>
<dd><p>Version of the output tool.</p>
<p>Default: False</p>
</dd>
</dl>
</section>
<section id="Sub-commands:">
<h2><span class="section-number">4.2. </span>Sub-commands:<a class="headerlink" href="#Sub-commands:" title="Permalink to this headline"></a></h2>
<section id="tf2onnx">
<h3><span class="section-number">4.2.1. </span>tf2onnx<a class="headerlink" href="#tf2onnx" title="Permalink to this headline"></a></h3>
<p>convert tensorflow model to onnx.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">poprt</span> <span class="n">tf2onnx</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">saved_model</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">signature_def</span> <span class="n">SIGNATURE_DEF</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">tag</span> <span class="n">TAG</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">inputs</span> <span class="n">INPUTS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">outputs</span> <span class="n">OUTPUTS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">opset</span> <span class="n">OPSET</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">inputs_as_nchw</span> <span class="n">INPUTS_AS_NCHW</span><span class="p">]</span>
              <span class="p">[</span><span class="o">--</span><span class="n">outputs_as_nchw</span> <span class="n">OUTPUTS_AS_NCHW</span><span class="p">]</span>
</pre></div>
</div>
<section id="Named Arguments_repeat1">
<h4>Named Arguments<a class="headerlink" href="#Named Arguments_repeat1" title="Permalink to this headline"></a></h4>
<dl class="option-list">
<dt><kbd>--saved_model</kbd></dt>
<dd><p>Specify if is saved_model. Use input_model to specify model path.</p>
<p>Default: False</p>
</dd>
<dt><kbd>--signature_def</kbd></dt>
<dd><p>signature_def from saved_model to use.</p>
</dd>
<dt><kbd>--tag</kbd></dt>
<dd><p>tag to use for saved_model.</p>
</dd>
<dt><kbd>--inputs</kbd></dt>
<dd><p>model input_names (optional for saved_model).</p>
</dd>
<dt><kbd>--outputs</kbd></dt>
<dd><p>model output_names (optional for saved_model).</p>
</dd>
<dt><kbd>--opset</kbd></dt>
<dd><p>opset version to use for onnx domain in tf frontend.</p>
<p>Default: 11</p>
</dd>
<dt><kbd>--inputs_as_nchw</kbd></dt>
<dd><p>transpose inputs as from nhwc to nchw.</p>
</dd>
<dt><kbd>--outputs_as_nchw</kbd></dt>
<dd><p>transpose outputs as from nhwc to nchw.</p>
</dd>
</dl>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start.html" class="btn btn-neutral float-left" title="3. Quick start" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="features/index.html" class="btn btn-neutral float-right" title="5. Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
     
    <script id="hs-script-loader" async defer src="//js.hs-scripts.com/729091.js"></script>
    <script defer>
        if (typeof mutationObserver !== 'undefined')
            mutationObserver.observe(document.querySelector("div.rst-other-versions"), {childList: true, subtree: true})
        if (typeof updateDocumentLinks !== 'undefined')
            updateDocumentLinks()
        let search = document.querySelector("form#rtd-search-form > input[name='q']")
        if (document.location.pathname.startsWith("/projects/"))
          search.placeholder = "Search this document";
        else
          search.placeholder = "Search all documents";
    </script>


</body>
</html>