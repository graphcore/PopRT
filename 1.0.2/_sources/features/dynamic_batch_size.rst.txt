.. _features_dynamic_batch_size:

使用 Dynamic Batch Size
=======================

背景
----

由于 IPU 仅支持静态图, 在模型编译阶段需要指定固定的 batch size. 而在实际推理过程中, 输入数据的 batch size 通常情况下是不固定的. PopRT 通过补 0 的方式支持任意 batch size 大小的输入数据. 例如, :numref:`dynamic_batch_size` 中模型的 shape 大小为 [4, 2], 并且 batch size 的维度是 0, 即 batch size 为 4. 而输入的数据 shape 大小分别为 [1, 2] 和 [7, 2], 即 batch size 分别为 1 和 7.

.. figure:: ../../images/dynamic_batch_size.png
    :align: center
    :name: dynamic_batch_size
    :width: 80%

    Dynamic Batch Size

PopRT 通过补 0 将数据扩展为最近的 N * 模型 batch size 大小的数据. 比如上述的 batch size 为 1 的数据会通过补 0 扩展到 batch size 为 4 的大小, 而 batch size 为 7 的数据会扩展为 batch size 为 8 的大小. 在 IPU 中数据会按照模型的 batch size 进行推理, 如上述扩展后 batch size 为 4 的数据一次推理得到结果后返回, 而 batch size 为 8 的数据会循环推理两次后返回结果.

动态 batch size 的功能对于用户程序来说是透明的, 用户无需关心当前 IPU 中加载模型的 batch size 大小, 按照应用的需求发送推理请求数据就可以了.

示例
----

:numref:`dynamic_batch_size_py` 中是动态 batch size 的示例代码. 示例中创建一个输入 shape 为 [4, 2] 的模型, 其 batch size 为 4. 应用程序分别使用 batch size 为 1, 4, 7 的数据进行推理, 无需考虑加载模型的 batch size 大小.

.. literalinclude:: ../../../examples/dynamic_batch_size.py
    :name: dynamic_batch_size_py
    :caption: dynamic_batch_size.py
    :language: python
    :linenos:

.. only:: html

    :download:`Download dynamic_batch_size.py <../../../examples/dynamic_batch_size.py>`

运行示例得到如下的输出信息:

.. code-block:: console

    Successfully run with input data in batch size 1
    Successfully run with input data in batch size 4
    Successfully run with input data in batch size 7
